{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        " 드라이브 마운트\n",
        " * local로 가져와서 압축풀기"
      ],
      "metadata": {
        "id": "QG6RJTGtabhu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, shutil, zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "# (Colab이면) 드라이브 마운트\n",
        "IN_COLAB = \"COLAB_GPU\" in os.environ or \"COLAB_TPU_ADDR\" in os.environ\n",
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount(\"/content/drive\")\n",
        "\n",
        "# ✅ 너 드라이브 원본 zip 위치\n",
        "DRIVE_DIR = Path(\"/content/drive/MyDrive/3.개방데이터\")\n",
        "\n",
        "# ✅ 새로 만들 로컬 작업 폴더 (기존꺼 삭제하고 새로)\n",
        "LOCAL_DIR = Path(\"/content/data_71802_local\")\n",
        "\n",
        "# ✅ 옵션: 로컬에 zip 복사본을 남길지\n",
        "KEEP_LOCAL_ZIPS = False\n",
        "\n",
        "# 0) 기존 로컬 폴더 삭제(완전 초기화)\n",
        "if LOCAL_DIR.exists():\n",
        "    shutil.rmtree(LOCAL_DIR)\n",
        "LOCAL_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 1) zip 찾기\n",
        "zips = sorted(DRIVE_DIR.rglob(\"*.zip\"))\n",
        "print(\"[INFO] zip found:\", len(zips))\n",
        "assert len(zips) > 0, \"DRIVE_DIR에서 zip을 못 찾았어. DRIVE_DIR 경로 확인해줘.\"\n",
        "\n",
        "# 2) 압축해제 출력 폴더\n",
        "EXTRACT_ROOT = LOCAL_DIR / \"extracted\"\n",
        "EXTRACT_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 3) zip별로 압축해제 (필요하면 로컬에 잠깐 복사 → 해제 → zip 삭제)\n",
        "for i, zp in enumerate(zips, 1):\n",
        "    print(f\"[{i}/{len(zips)}] unzip:\", zp)\n",
        "\n",
        "    # zip을 로컬에 복사할지 여부\n",
        "    if KEEP_LOCAL_ZIPS:\n",
        "        local_zip = LOCAL_DIR / \"zips\" / zp.name\n",
        "        local_zip.parent.mkdir(parents=True, exist_ok=True)\n",
        "        if not local_zip.exists():\n",
        "            shutil.copy2(zp, local_zip)\n",
        "        zip_to_open = local_zip\n",
        "    else:\n",
        "        # 드라이브에서 바로 풀기(느릴 수 있음). 느리면 True로 바꿔서 로컬 복사 후 풀어.\n",
        "        zip_to_open = zp\n",
        "\n",
        "    out_dir = EXTRACT_ROOT / zp.stem\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # 이미 풀렸는지 간단 체크(폴더에 뭐라도 있으면 스킵)\n",
        "    if any(out_dir.rglob(\"*\")):\n",
        "        print(\"  -> already extracted, skip\")\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        with zipfile.ZipFile(zip_to_open, \"r\") as zf:\n",
        "            zf.extractall(out_dir)\n",
        "        print(\"  -> done\")\n",
        "    except Exception as e:\n",
        "        print(\"  -> [WARN] failed:\", e)\n",
        "\n",
        "# 4) 로컬 zip 복사본 지우기 (KEEP_LOCAL_ZIPS=False이면 애초에 안 생김)\n",
        "if not KEEP_LOCAL_ZIPS:\n",
        "    # 로컬에 zip을 따로 복사하지 않았으니 할 일 없음\n",
        "    pass\n",
        "\n",
        "# ✅ 최종 BASE_DIR: 압축해제된 데이터 루트\n",
        "BASE_DIR = EXTRACT_ROOT\n",
        "print(\"[INFO] BASE_DIR:\", BASE_DIR)\n",
        "\n",
        "# (검증) csv/bin/json 개수 확인\n",
        "exts = {\"csv\":0,\"bin\":0,\"json\":0,\"zip\":0}\n",
        "for p in BASE_DIR.rglob(\"*\"):\n",
        "    if p.is_file():\n",
        "        s = p.suffix.lower().lstrip(\".\")\n",
        "        if s in exts: exts[s] += 1\n",
        "print(\"[INFO] extracted counts:\", exts)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a29qJ7-R7fFW",
        "outputId": "e0db2962-6fd8-4d59-b7fe-a68e38aaea14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "[INFO] zip found: 683\n",
            "[1/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Other/Other.zip\n",
            "  -> done\n",
            "[2/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_01_agv01_0901_0812.zip\n",
            "  -> done\n",
            "[3/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_01_agv01_0902_1253.zip\n",
            "  -> done\n",
            "[4/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_01_agv01_0902_2013.zip\n",
            "  -> done\n",
            "[5/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_01_agv01_0903_1018.zip\n",
            "  -> done\n",
            "[6/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_01_agv01_0903_1407.zip\n",
            "  -> done\n",
            "[7/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_01_agv01_1027_0724.zip\n",
            "  -> done\n",
            "[8/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_01_agv01_1027_1405.zip\n",
            "  -> done\n",
            "[9/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_02_agv02_0901_0826.zip\n",
            "  -> done\n",
            "[10/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_02_agv02_0902_1306.zip\n",
            "  -> done\n",
            "[11/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_02_agv02_0902_2034.zip\n",
            "  -> done\n",
            "[12/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_02_agv02_0903_1029.zip\n",
            "  -> done\n",
            "[13/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_02_agv02_1024_1025.zip\n",
            "  -> done\n",
            "[14/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_02_agv02_1027_0734.zip\n",
            "  -> done\n",
            "[15/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_02_agv02_1027_1427.zip\n",
            "  -> done\n",
            "[16/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_03_agv03_0901_0909.zip\n",
            "  -> done\n",
            "[17/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_03_agv03_0902_1320.zip\n",
            "  -> done\n",
            "[18/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_03_agv03_0902_2043.zip\n",
            "  -> done\n",
            "[19/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_03_agv03_0903_1039.zip\n",
            "  -> done\n",
            "[20/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_03_agv03_1024_1052.zip\n",
            "  -> done\n",
            "[21/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_03_agv03_1027_0745.zip\n",
            "  -> done\n",
            "[22/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_03_agv03_1027_1439.zip\n",
            "  -> done\n",
            "[23/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_04_agv04_0901_0918.zip\n",
            "  -> done\n",
            "[24/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_04_agv04_0902_1333.zip\n",
            "  -> done\n",
            "[25/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_04_agv04_0903_0343.zip\n",
            "  -> done\n",
            "[26/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_04_agv04_0903_1049.zip\n",
            "  -> done\n",
            "[27/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_04_agv04_1024_1105.zip\n",
            "  -> done\n",
            "[28/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_04_agv04_1027_0755.zip\n",
            "  -> done\n",
            "[29/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_04_agv04_1027_1501.zip\n",
            "  -> done\n",
            "[30/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_05_agv05_0901_0924.zip\n",
            "  -> done\n",
            "[31/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_05_agv05_0902_1345.zip\n",
            "  -> done\n",
            "[32/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_05_agv05_0903_0409.zip\n",
            "  -> done\n",
            "[33/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_05_agv05_0903_1059.zip\n",
            "  -> done\n",
            "[34/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_05_agv05_1024_1118.zip\n",
            "  -> done\n",
            "[35/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_05_agv05_1027_0826.zip\n",
            "  -> done\n",
            "[36/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_05_agv05_1027_1511.zip\n",
            "  -> done\n",
            "[37/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_06_agv06_0901_0938.zip\n",
            "  -> done\n",
            "[38/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_06_agv06_0902_1356.zip\n",
            "  -> done\n",
            "[39/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_06_agv06_0903_0429.zip\n",
            "  -> done\n",
            "[40/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_06_agv06_0903_1110.zip\n",
            "  -> done\n",
            "[41/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_06_agv06_1024_1132.zip\n",
            "  -> done\n",
            "[42/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_06_agv06_1027_0836.zip\n",
            "  -> done\n",
            "[43/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_06_agv06_1027_1522.zip\n",
            "  -> done\n",
            "[44/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_07_agv07_0901_0945.zip\n",
            "  -> done\n",
            "[45/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_07_agv07_0902_1406.zip\n",
            "  -> done\n",
            "[46/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_07_agv07_0903_0439.zip\n",
            "  -> done\n",
            "[47/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_07_agv07_0903_1120.zip\n",
            "  -> done\n",
            "[48/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_07_agv07_1024_1419.zip\n",
            "  -> done\n",
            "[49/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_07_agv07_1027_0848.zip\n",
            "  -> done\n",
            "[50/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_07_agv07_1027_1534.zip\n",
            "  -> done\n",
            "[51/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_08_agv08_0901_1001.zip\n",
            "  -> done\n",
            "[52/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_08_agv08_0902_1453.zip\n",
            "  -> done\n",
            "[53/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_08_agv08_0903_0450.zip\n",
            "  -> done\n",
            "[54/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_08_agv08_0903_1131.zip\n",
            "  -> done\n",
            "[55/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_08_agv08_1024_1619.zip\n",
            "  -> done\n",
            "[56/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_08_agv08_1027_0932.zip\n",
            "  -> done\n",
            "[57/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_08_agv08_1027_1546.zip\n",
            "  -> done\n",
            "[58/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_09_agv09_0901_1011.zip\n",
            "  -> done\n",
            "[59/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_09_agv09_0902_1504.zip\n",
            "  -> done\n",
            "[60/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_09_agv09_0903_0500.zip\n",
            "  -> done\n",
            "[61/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_09_agv09_0903_1143.zip\n",
            "  -> done\n",
            "[62/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_09_agv09_1026_2140.zip\n",
            "  -> done\n",
            "[63/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_09_agv09_1027_0957.zip\n",
            "  -> done\n",
            "[64/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_09_agv09_1027_1623.zip\n",
            "  -> done\n",
            "[65/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_10_agv10_0901_1024.zip\n",
            "  -> done\n",
            "[66/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_10_agv10_0902_1523.zip\n",
            "  -> done\n",
            "[67/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_10_agv10_0903_0531.zip\n",
            "  -> done\n",
            "[68/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_10_agv10_0903_1156.zip\n",
            "  -> done\n",
            "[69/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_10_agv10_1026_2152.zip\n",
            "  -> done\n",
            "[70/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_10_agv10_1027_1008.zip\n",
            "  -> done\n",
            "[71/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_10_agv10_1027_1651.zip\n",
            "  -> done\n",
            "[72/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_11_agv11_0901_1034.zip\n",
            "  -> done\n",
            "[73/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_11_agv11_0902_1536.zip\n",
            "  -> done\n",
            "[74/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_11_agv11_0903_0541.zip\n",
            "  -> done\n",
            "[75/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_11_agv11_0903_1206.zip\n",
            "  -> done\n",
            "[76/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_11_agv11_1026_2203.zip\n",
            "  -> done\n",
            "[77/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_11_agv11_1027_1017.zip\n",
            "  -> done\n",
            "[78/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_11_agv11_1027_1702.zip\n",
            "  -> done\n",
            "[79/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_12_agv12_0901_0846.zip\n",
            "  -> done\n",
            "[80/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_12_agv12_0901_1045.zip\n",
            "  -> done\n",
            "[81/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_12_agv12_0902_1619.zip\n",
            "  -> done\n",
            "[82/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_12_agv12_0903_0553.zip\n",
            "  -> done\n",
            "[83/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_12_agv12_0903_1216.zip\n",
            "  -> done\n",
            "[84/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_12_agv12_1026_2224.zip\n",
            "  -> done\n",
            "[85/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_12_agv12_1027_1027.zip\n",
            "  -> done\n",
            "[86/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_13_agv13_0901_0900.zip\n",
            "  -> done\n",
            "[87/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_13_agv13_0902_0923.zip\n",
            "  -> done\n",
            "[88/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_13_agv13_0902_1820.zip\n",
            "  -> done\n",
            "[89/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_13_agv13_0903_0637.zip\n",
            "  -> done\n",
            "[90/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_13_agv13_0903_1226.zip\n",
            "  -> done\n",
            "[91/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_13_agv13_1026_2235.zip\n",
            "  -> done\n",
            "[92/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_13_agv13_1027_1048.zip\n",
            "  -> done\n",
            "[93/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_14_agv14_0901_0952.zip\n",
            "  -> done\n",
            "[94/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_14_agv14_0902_0945.zip\n",
            "  -> done\n",
            "[95/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_14_agv14_0902_1832.zip\n",
            "  -> done\n",
            "[96/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_14_agv14_0903_0650.zip\n",
            "  -> done\n",
            "[97/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_14_agv14_0903_1239.zip\n",
            "  -> done\n",
            "[98/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_14_agv14_1026_2245.zip\n",
            "  -> done\n",
            "[99/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_14_agv14_1027_1059.zip\n",
            "  -> done\n",
            "[100/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_15_agv15_0902_0957.zip\n",
            "  -> done\n",
            "[101/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_15_agv15_0902_1032.zip\n",
            "  -> done\n",
            "[102/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_15_agv15_0902_1845.zip\n",
            "  -> done\n",
            "[103/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_15_agv15_0903_0712.zip\n",
            "  -> done\n",
            "[104/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_15_agv15_0903_1250.zip\n",
            "  -> done\n",
            "[105/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_15_agv15_1026_2308.zip\n",
            "  -> done\n",
            "[106/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_15_agv15_1027_1120.zip\n",
            "  -> done\n",
            "[107/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_16_agv16_0902_1022.zip\n",
            "  -> done\n",
            "[108/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_16_agv16_0902_1857.zip\n",
            "  -> done\n",
            "[109/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_16_agv16_0903_0722.zip\n",
            "  -> done\n",
            "[110/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_16_agv16_0903_1314.zip\n",
            "  -> done\n",
            "[111/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_16_agv16_1026_2329.zip\n",
            "  -> done\n",
            "[112/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_16_agv16_1027_0945.zip\n",
            "  -> done\n",
            "[113/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_agv_16_agv16_1027_1303.zip\n",
            "  -> done\n",
            "[114/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_01_oht01_0826_2037.zip\n",
            "  -> done\n",
            "[115/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_01_oht01_0827_0041.zip\n",
            "  -> done\n",
            "[116/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_01_oht01_0827_0330.zip\n",
            "  -> done\n",
            "[117/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_01_oht01_0827_0556.zip\n",
            "  -> done\n",
            "[118/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_01_oht01_0827_0901.zip\n",
            "  -> done\n",
            "[119/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_01_oht01_0901_1205.zip\n",
            "  -> done\n",
            "[120/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_01_oht01_0902_1338.zip\n",
            "  -> done\n",
            "[121/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_01_oht01_0906_0330.zip\n",
            "  -> done\n",
            "[122/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_01_oht01_0920_0734.zip\n",
            "  -> done\n",
            "[123/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_01_oht01_0920_1518.zip\n",
            "  -> done\n",
            "[124/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_01_oht01_0920_1912.zip\n",
            "  -> done\n",
            "[125/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_01_oht01_0920_2042.zip\n",
            "  -> done\n",
            "[126/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_02_oht02_0826_2038.zip\n",
            "  -> done\n",
            "[127/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_02_oht02_0827_0101.zip\n",
            "  -> done\n",
            "[128/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_02_oht02_0827_0343.zip\n",
            "  -> done\n",
            "[129/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_02_oht02_0827_0558.zip\n",
            "  -> done\n",
            "[130/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_02_oht02_0827_0910.zip\n",
            "  -> done\n",
            "[131/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_02_oht02_0901_1218.zip\n",
            "  -> done\n",
            "[132/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_02_oht02_0902_1345.zip\n",
            "  -> done\n",
            "[133/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_02_oht02_0906_0756.zip\n",
            "  -> done\n",
            "[134/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_02_oht02_0920_0746.zip\n",
            "  -> done\n",
            "[135/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_02_oht02_0920_1020.zip\n",
            "  -> done\n",
            "[136/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_02_oht02_0920_1623.zip\n",
            "  -> done\n",
            "[137/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_02_oht02_0920_2055.zip\n",
            "  -> done\n",
            "[138/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_03_oht03_0826_2049.zip\n",
            "  -> done\n",
            "[139/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_03_oht03_0826_2151.zip\n",
            "  -> done\n",
            "[140/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_03_oht03_0827_0109.zip\n",
            "  -> done\n",
            "[141/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_03_oht03_0827_0353.zip\n",
            "  -> done\n",
            "[142/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_03_oht03_0827_0605.zip\n",
            "  -> done\n",
            "[143/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_03_oht03_0827_0920.zip\n",
            "  -> done\n",
            "[144/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_03_oht03_0901_1227.zip\n",
            "  -> done\n",
            "[145/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_03_oht03_0902_1357.zip\n",
            "  -> done\n",
            "[146/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_03_oht03_0910_0841.zip\n",
            "  -> done\n",
            "[147/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_03_oht03_0920_0800.zip\n",
            "  -> done\n",
            "[148/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_03_oht03_0920_1634.zip\n",
            "  -> done\n",
            "[149/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_03_oht03_0920_2106.zip\n",
            "  -> done\n",
            "[150/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_04_oht04_0826_2056.zip\n",
            "  -> done\n",
            "[151/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_04_oht04_0827_0119.zip\n",
            "  -> done\n",
            "[152/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_04_oht04_0827_0403.zip\n",
            "  -> done\n",
            "[153/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_04_oht04_0827_0608.zip\n",
            "  -> done\n",
            "[154/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_04_oht04_0827_0947.zip\n",
            "  -> done\n",
            "[155/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_04_oht04_0901_1245.zip\n",
            "  -> done\n",
            "[156/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_04_oht04_0902_1415.zip\n",
            "  -> done\n",
            "[157/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_04_oht04_0911_0556.zip\n",
            "  -> done\n",
            "[158/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_04_oht04_0920_0811.zip\n",
            "  -> done\n",
            "[159/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_04_oht04_0920_1644.zip\n",
            "  -> done\n",
            "[160/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_04_oht04_0920_2118.zip\n",
            "  -> done\n",
            "[161/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_05_oht05_0826_1611.zip\n",
            "  -> done\n",
            "[162/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_05_oht05_0826_2059.zip\n",
            "  -> done\n",
            "[163/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_05_oht05_0827_0129.zip\n",
            "  -> done\n",
            "[164/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_05_oht05_0827_0405.zip\n",
            "  -> done\n",
            "[165/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_05_oht05_0827_0618.zip\n",
            "  -> done\n",
            "[166/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_05_oht05_0827_0846.zip\n",
            "  -> done\n",
            "[167/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_05_oht05_0827_0958.zip\n",
            "  -> done\n",
            "[168/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_05_oht05_0901_1252.zip\n",
            "  -> done\n",
            "[169/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_05_oht05_0902_1424.zip\n",
            "  -> done\n",
            "[170/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_05_oht05_0914_0632.zip\n",
            "  -> done\n",
            "[171/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_05_oht05_0920_0824.zip\n",
            "  -> done\n",
            "[172/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_05_oht05_0920_1654.zip\n",
            "  -> done\n",
            "[173/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_06_oht06_0826_1944.zip\n",
            "  -> done\n",
            "[174/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_06_oht06_0826_2243.zip\n",
            "  -> done\n",
            "[175/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_06_oht06_0827_0238.zip\n",
            "  -> done\n",
            "[176/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_06_oht06_0827_0514.zip\n",
            "  -> done\n",
            "[177/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_06_oht06_0827_0814.zip\n",
            "  -> done\n",
            "[178/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_06_oht06_0827_0859.zip\n",
            "  -> done\n",
            "[179/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_06_oht06_0901_1238.zip\n",
            "  -> done\n",
            "[180/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_06_oht06_0901_1310.zip\n",
            "  -> done\n",
            "[181/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_06_oht06_0903_0615.zip\n",
            "  -> done\n",
            "[182/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_06_oht06_0920_0448.zip\n",
            "  -> done\n",
            "[183/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_06_oht06_0920_1010.zip\n",
            "  -> done\n",
            "[184/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_06_oht06_0920_1922.zip\n",
            "  -> done\n",
            "[185/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_07_oht07_0826_1955.zip\n",
            "  -> done\n",
            "[186/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_07_oht07_0826_2253.zip\n",
            "  -> done\n",
            "[187/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_07_oht07_0827_0245.zip\n",
            "  -> done\n",
            "[188/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_07_oht07_0827_0515.zip\n",
            "  -> done\n",
            "[189/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_07_oht07_0827_0822.zip\n",
            "  -> done\n",
            "[190/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_07_oht07_0828_0728.zip\n",
            "  -> done\n",
            "[191/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_07_oht07_0901_1302.zip\n",
            "  -> done\n",
            "[192/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_07_oht07_0901_1316.zip\n",
            "  -> done\n",
            "[193/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_07_oht07_0903_0708.zip\n",
            "  -> done\n",
            "[194/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_07_oht07_0920_0502.zip\n",
            "  -> done\n",
            "[195/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_07_oht07_0920_1030.zip\n",
            "  -> done\n",
            "[196/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_07_oht07_0920_1932.zip\n",
            "  -> done\n",
            "[197/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_08_oht08_0826_2006.zip\n",
            "  -> done\n",
            "[198/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_08_oht08_0826_2332.zip\n",
            "  -> done\n",
            "[199/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_08_oht08_0827_0250.zip\n",
            "  -> done\n",
            "[200/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_08_oht08_0827_0525.zip\n",
            "  -> done\n",
            "[201/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_08_oht08_0827_0823.zip\n",
            "  -> done\n",
            "[202/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_08_oht08_0830_0223.zip\n",
            "  -> done\n",
            "[203/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_08_oht08_0901_1322.zip\n",
            "  -> done\n",
            "[204/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_08_oht08_0901_1416.zip\n",
            "  -> done\n",
            "[205/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_08_oht08_0903_0910.zip\n",
            "  -> done\n",
            "[206/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_08_oht08_0920_0516.zip\n",
            "  -> done\n",
            "[207/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_08_oht08_0920_1041.zip\n",
            "  -> done\n",
            "[208/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_08_oht08_0920_1942.zip\n",
            "  -> done\n",
            "[209/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_09_oht09_0826_2016.zip\n",
            "  -> done\n",
            "[210/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_09_oht09_0827_0001.zip\n",
            "  -> done\n",
            "[211/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_09_oht09_0827_0301.zip\n",
            "  -> done\n",
            "[212/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_09_oht09_0827_0535.zip\n",
            "  -> done\n",
            "[213/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_09_oht09_0827_0830.zip\n",
            "  -> done\n",
            "[214/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_09_oht09_0901_1331.zip\n",
            "  -> done\n",
            "[215/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_09_oht09_0902_1230.zip\n",
            "  -> done\n",
            "[216/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_09_oht09_0904_0405.zip\n",
            "  -> done\n",
            "[217/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_09_oht09_0906_0256.zip\n",
            "  -> done\n",
            "[218/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_09_oht09_0920_0642.zip\n",
            "  -> done\n",
            "[219/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_09_oht09_0920_1051.zip\n",
            "  -> done\n",
            "[220/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_09_oht09_0920_1952.zip\n",
            "  -> done\n",
            "[221/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_10_oht10_0826_2027.zip\n",
            "  -> done\n",
            "[222/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_10_oht10_0827_0021.zip\n",
            "  -> done\n",
            "[223/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_10_oht10_0827_0306.zip\n",
            "  -> done\n",
            "[224/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_10_oht10_0827_0545.zip\n",
            "  -> done\n",
            "[225/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_10_oht10_0827_0835.zip\n",
            "  -> done\n",
            "[226/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_10_oht10_0901_1337.zip\n",
            "  -> done\n",
            "[227/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_10_oht10_0902_1404.zip\n",
            "  -> done\n",
            "[228/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_10_oht10_0905_0535.zip\n",
            "  -> done\n",
            "[229/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_10_oht10_0920_0307.zip\n",
            "  -> done\n",
            "[230/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_10_oht10_0920_0654.zip\n",
            "  -> done\n",
            "[231/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_10_oht10_0920_1415.zip\n",
            "  -> done\n",
            "[232/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_10_oht10_0920_2003.zip\n",
            "  -> done\n",
            "[233/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_11_oht11_0826_2029.zip\n",
            "  -> done\n",
            "[234/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_11_oht11_0827_0031.zip\n",
            "  -> done\n",
            "[235/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_11_oht11_0827_0318.zip\n",
            "  -> done\n",
            "[236/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_11_oht11_0827_0546.zip\n",
            "  -> done\n",
            "[237/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_11_oht11_0827_0841.zip\n",
            "  -> done\n",
            "[238/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_11_oht11_0901_1344.zip\n",
            "  -> done\n",
            "[239/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_11_oht11_0906_0306.zip\n",
            "  -> done\n",
            "[240/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_11_oht11_0920_0706.zip\n",
            "  -> done\n",
            "[241/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_11_oht11_0920_0719.zip\n",
            "  -> done\n",
            "[242/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_11_oht11_0920_1439.zip\n",
            "  -> done\n",
            "[243/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_11_oht11_0920_2029.zip\n",
            "  -> done\n",
            "[244/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_11_oht11_1024_1025.zip\n",
            "  -> done\n",
            "[245/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_12_oht12_0826_1352.zip\n",
            "  -> done\n",
            "[246/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_12_oht12_0826_1625.zip\n",
            "  -> done\n",
            "[247/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_12_oht12_0826_2106.zip\n",
            "  -> done\n",
            "[248/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_12_oht12_0826_2130.zip\n",
            "  -> done\n",
            "[249/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_12_oht12_0827_0139.zip\n",
            "  -> done\n",
            "[250/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_12_oht12_0827_0414.zip\n",
            "  -> done\n",
            "[251/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_12_oht12_0827_0623.zip\n",
            "  -> done\n",
            "[252/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_12_oht12_0828_0420.zip\n",
            "  -> done\n",
            "[253/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_12_oht12_0901_1353.zip\n",
            "  -> done\n",
            "[254/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_12_oht12_0920_0242.zip\n",
            "  -> done\n",
            "[255/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_12_oht12_0920_0835.zip\n",
            "  -> done\n",
            "[256/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_12_oht12_0920_1704.zip\n",
            "  -> done\n",
            "[257/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_13_oht13_0826_1404.zip\n",
            "  -> done\n",
            "[258/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_13_oht13_0826_1751.zip\n",
            "  -> done\n",
            "[259/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_13_oht13_0826_2109.zip\n",
            "  -> done\n",
            "[260/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_13_oht13_0826_2140.zip\n",
            "  -> done\n",
            "[261/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_13_oht13_0827_0148.zip\n",
            "  -> done\n",
            "[262/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_13_oht13_0827_0420.zip\n",
            "  -> done\n",
            "[263/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_13_oht13_0827_0641.zip\n",
            "  -> done\n",
            "[264/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_13_oht13_0828_0947.zip\n",
            "  -> done\n",
            "[265/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_13_oht13_0901_1403.zip\n",
            "  -> done\n",
            "[266/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_13_oht13_0920_0254.zip\n",
            "  -> done\n",
            "[267/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_13_oht13_0920_0846.zip\n",
            "  -> done\n",
            "[268/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_13_oht13_0920_1714.zip\n",
            "  -> done\n",
            "[269/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_14_oht14_0826_1416.zip\n",
            "  -> done\n",
            "[270/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_14_oht14_0826_1803.zip\n",
            "  -> done\n",
            "[271/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_14_oht14_0826_2119.zip\n",
            "  -> done\n",
            "[272/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_14_oht14_0826_2234.zip\n",
            "  -> done\n",
            "[273/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_14_oht14_0827_0158.zip\n",
            "  -> done\n",
            "[274/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_14_oht14_0827_0424.zip\n",
            "  -> done\n",
            "[275/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_14_oht14_0827_0652.zip\n",
            "  -> done\n",
            "[276/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_14_oht14_0829_0525.zip\n",
            "  -> done\n",
            "[277/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_14_oht14_0901_1426.zip\n",
            "  -> done\n",
            "[278/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_14_oht14_0920_0319.zip\n",
            "  -> done\n",
            "[279/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_14_oht14_0920_0856.zip\n",
            "  -> done\n",
            "[280/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_14_oht14_0920_1724.zip\n",
            "  -> done\n",
            "[281/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_15_oht15_0826_1429.zip\n",
            "  -> done\n",
            "[282/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_15_oht15_0826_1816.zip\n",
            "  -> done\n",
            "[283/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_15_oht15_0826_2126.zip\n",
            "  -> done\n",
            "[284/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_15_oht15_0826_2312.zip\n",
            "  -> done\n",
            "[285/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_15_oht15_0827_0200.zip\n",
            "  -> done\n",
            "[286/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_15_oht15_0827_0431.zip\n",
            "  -> done\n",
            "[287/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_15_oht15_0827_0708.zip\n",
            "  -> done\n",
            "[288/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_15_oht15_0829_0605.zip\n",
            "  -> done\n",
            "[289/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_15_oht15_0901_1437.zip\n",
            "  -> done\n",
            "[290/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_15_oht15_0920_0332.zip\n",
            "  -> done\n",
            "[291/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_15_oht15_0920_0907.zip\n",
            "  -> done\n",
            "[292/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_15_oht15_0920_1745.zip\n",
            "  -> done\n",
            "[293/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_16_oht16_0826_1441.zip\n",
            "  -> done\n",
            "[294/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_16_oht16_0826_1829.zip\n",
            "  -> done\n",
            "[295/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_16_oht16_0826_2137.zip\n",
            "  -> done\n",
            "[296/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_16_oht16_0827_0208.zip\n",
            "  -> done\n",
            "[297/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_16_oht16_0827_0219.zip\n",
            "  -> done\n",
            "[298/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_16_oht16_0827_0434.zip\n",
            "  -> done\n",
            "[299/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_16_oht16_0827_0713.zip\n",
            "  -> done\n",
            "[300/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_16_oht16_0830_0658.zip\n",
            "  -> done\n",
            "[301/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_16_oht16_0902_1241.zip\n",
            "  -> done\n",
            "[302/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_16_oht16_0920_0344.zip\n",
            "  -> done\n",
            "[303/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_16_oht16_0920_0917.zip\n",
            "  -> done\n",
            "[304/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/01.원천데이터/TS_oht_16_oht16_0920_1756.zip\n",
            "  -> done\n",
            "[305/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_01_agv01_0901_0812.zip\n",
            "  -> done\n",
            "[306/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_01_agv01_0902_1253.zip\n",
            "  -> done\n",
            "[307/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_01_agv01_0902_2013.zip\n",
            "  -> done\n",
            "[308/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_01_agv01_0903_1018.zip\n",
            "  -> done\n",
            "[309/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_01_agv01_0903_1407.zip\n",
            "  -> done\n",
            "[310/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_01_agv01_1027_0724.zip\n",
            "  -> done\n",
            "[311/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_01_agv01_1027_1405.zip\n",
            "  -> done\n",
            "[312/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_02_agv02_0901_0826.zip\n",
            "  -> done\n",
            "[313/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_02_agv02_0902_1306.zip\n",
            "  -> done\n",
            "[314/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_02_agv02_0902_2034.zip\n",
            "  -> done\n",
            "[315/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_02_agv02_0903_1029.zip\n",
            "  -> done\n",
            "[316/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_02_agv02_1024_1025.zip\n",
            "  -> done\n",
            "[317/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_02_agv02_1027_0734.zip\n",
            "  -> done\n",
            "[318/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_02_agv02_1027_1427.zip\n",
            "  -> done\n",
            "[319/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_03_agv03_0901_0909.zip\n",
            "  -> done\n",
            "[320/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_03_agv03_0902_1320.zip\n",
            "  -> done\n",
            "[321/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_03_agv03_0902_2043.zip\n",
            "  -> done\n",
            "[322/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_03_agv03_0903_1039.zip\n",
            "  -> done\n",
            "[323/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_03_agv03_1024_1052.zip\n",
            "  -> done\n",
            "[324/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_03_agv03_1027_0745.zip\n",
            "  -> done\n",
            "[325/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_03_agv03_1027_1439.zip\n",
            "  -> done\n",
            "[326/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_04_agv04_0901_0918.zip\n",
            "  -> done\n",
            "[327/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_04_agv04_0902_1333.zip\n",
            "  -> done\n",
            "[328/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_04_agv04_0903_0343.zip\n",
            "  -> done\n",
            "[329/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_04_agv04_0903_1049.zip\n",
            "  -> done\n",
            "[330/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_04_agv04_1024_1105.zip\n",
            "  -> done\n",
            "[331/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_04_agv04_1027_0755.zip\n",
            "  -> done\n",
            "[332/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_04_agv04_1027_1501.zip\n",
            "  -> done\n",
            "[333/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_05_agv05_0901_0924.zip\n",
            "  -> done\n",
            "[334/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_05_agv05_0902_1345.zip\n",
            "  -> done\n",
            "[335/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_05_agv05_0903_0409.zip\n",
            "  -> done\n",
            "[336/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_05_agv05_0903_1059.zip\n",
            "  -> done\n",
            "[337/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_05_agv05_1024_1118.zip\n",
            "  -> done\n",
            "[338/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_05_agv05_1027_0826.zip\n",
            "  -> done\n",
            "[339/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_05_agv05_1027_1511.zip\n",
            "  -> done\n",
            "[340/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_06_agv06_0901_0938.zip\n",
            "  -> done\n",
            "[341/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_06_agv06_0902_1356.zip\n",
            "  -> done\n",
            "[342/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_06_agv06_0903_0429.zip\n",
            "  -> done\n",
            "[343/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_06_agv06_0903_1110.zip\n",
            "  -> done\n",
            "[344/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_06_agv06_1024_1132.zip\n",
            "  -> done\n",
            "[345/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_06_agv06_1027_0836.zip\n",
            "  -> done\n",
            "[346/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_06_agv06_1027_1522.zip\n",
            "  -> done\n",
            "[347/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_07_agv07_0901_0945.zip\n",
            "  -> done\n",
            "[348/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_07_agv07_0902_1406.zip\n",
            "  -> done\n",
            "[349/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_07_agv07_0903_0439.zip\n",
            "  -> done\n",
            "[350/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_07_agv07_0903_1120.zip\n",
            "  -> done\n",
            "[351/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_07_agv07_1024_1419.zip\n",
            "  -> done\n",
            "[352/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_07_agv07_1027_0848.zip\n",
            "  -> done\n",
            "[353/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_07_agv07_1027_1534.zip\n",
            "  -> done\n",
            "[354/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_08_agv08_0901_1001.zip\n",
            "  -> done\n",
            "[355/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_08_agv08_0902_1453.zip\n",
            "  -> done\n",
            "[356/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_08_agv08_0903_0450.zip\n",
            "  -> done\n",
            "[357/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_08_agv08_0903_1131.zip\n",
            "  -> done\n",
            "[358/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_08_agv08_1024_1619.zip\n",
            "  -> done\n",
            "[359/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_08_agv08_1027_0932.zip\n",
            "  -> done\n",
            "[360/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_08_agv08_1027_1546.zip\n",
            "  -> done\n",
            "[361/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_09_agv09_0901_1011.zip\n",
            "  -> done\n",
            "[362/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_09_agv09_0902_1504.zip\n",
            "  -> done\n",
            "[363/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_09_agv09_0903_0500.zip\n",
            "  -> done\n",
            "[364/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_09_agv09_0903_1143.zip\n",
            "  -> done\n",
            "[365/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_09_agv09_1026_2140.zip\n",
            "  -> done\n",
            "[366/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_09_agv09_1027_0957.zip\n",
            "  -> done\n",
            "[367/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_09_agv09_1027_1623.zip\n",
            "  -> done\n",
            "[368/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_10_agv10_0901_1024.zip\n",
            "  -> done\n",
            "[369/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_10_agv10_0902_1523.zip\n",
            "  -> done\n",
            "[370/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_10_agv10_0903_0531.zip\n",
            "  -> done\n",
            "[371/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_10_agv10_0903_1156.zip\n",
            "  -> done\n",
            "[372/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_10_agv10_1026_2152.zip\n",
            "  -> done\n",
            "[373/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_10_agv10_1027_1008.zip\n",
            "  -> done\n",
            "[374/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_10_agv10_1027_1651.zip\n",
            "  -> done\n",
            "[375/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_11_agv11_0901_1034.zip\n",
            "  -> done\n",
            "[376/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_11_agv11_0902_1536.zip\n",
            "  -> done\n",
            "[377/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_11_agv11_0903_0541.zip\n",
            "  -> done\n",
            "[378/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_11_agv11_0903_1206.zip\n",
            "  -> done\n",
            "[379/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_11_agv11_1026_2203.zip\n",
            "  -> done\n",
            "[380/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_11_agv11_1027_1017.zip\n",
            "  -> done\n",
            "[381/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_11_agv11_1027_1702.zip\n",
            "  -> done\n",
            "[382/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_12_agv12_0901_0846.zip\n",
            "  -> done\n",
            "[383/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_12_agv12_0901_1045.zip\n",
            "  -> done\n",
            "[384/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_12_agv12_0902_1619.zip\n",
            "  -> done\n",
            "[385/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_12_agv12_0903_0553.zip\n",
            "  -> done\n",
            "[386/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_12_agv12_0903_1216.zip\n",
            "  -> done\n",
            "[387/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_12_agv12_1026_2224.zip\n",
            "  -> done\n",
            "[388/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_12_agv12_1027_1027.zip\n",
            "  -> done\n",
            "[389/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_13_agv13_0901_0900.zip\n",
            "  -> done\n",
            "[390/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_13_agv13_0902_0923.zip\n",
            "  -> done\n",
            "[391/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_13_agv13_0902_1820.zip\n",
            "  -> done\n",
            "[392/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_13_agv13_0903_0637.zip\n",
            "  -> done\n",
            "[393/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_13_agv13_0903_1226.zip\n",
            "  -> done\n",
            "[394/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_13_agv13_1026_2235.zip\n",
            "  -> done\n",
            "[395/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_13_agv13_1027_1048.zip\n",
            "  -> done\n",
            "[396/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_14_agv14_0901_0952.zip\n",
            "  -> done\n",
            "[397/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_14_agv14_0902_0945.zip\n",
            "  -> done\n",
            "[398/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_14_agv14_0902_1832.zip\n",
            "  -> done\n",
            "[399/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_14_agv14_0903_0650.zip\n",
            "  -> done\n",
            "[400/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_14_agv14_0903_1239.zip\n",
            "  -> done\n",
            "[401/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_14_agv14_1026_2245.zip\n",
            "  -> done\n",
            "[402/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_14_agv14_1027_1059.zip\n",
            "  -> done\n",
            "[403/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_15_agv15_0902_0957.zip\n",
            "  -> done\n",
            "[404/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_15_agv15_0902_1032.zip\n",
            "  -> done\n",
            "[405/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_15_agv15_0902_1845.zip\n",
            "  -> done\n",
            "[406/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_15_agv15_0903_0712.zip\n",
            "  -> done\n",
            "[407/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_15_agv15_0903_1250.zip\n",
            "  -> done\n",
            "[408/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_15_agv15_1026_2308.zip\n",
            "  -> done\n",
            "[409/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_15_agv15_1027_1120.zip\n",
            "  -> done\n",
            "[410/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_16_agv16_0902_1022.zip\n",
            "  -> done\n",
            "[411/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_16_agv16_0902_1857.zip\n",
            "  -> done\n",
            "[412/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_16_agv16_0903_0722.zip\n",
            "  -> done\n",
            "[413/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_16_agv16_0903_1314.zip\n",
            "  -> done\n",
            "[414/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_16_agv16_1026_2329.zip\n",
            "  -> done\n",
            "[415/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_16_agv16_1027_0945.zip\n",
            "  -> done\n",
            "[416/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_agv_16_agv16_1027_1303.zip\n",
            "  -> done\n",
            "[417/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_01_oht01_0826_2037.zip\n",
            "  -> done\n",
            "[418/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_01_oht01_0827_0041.zip\n",
            "  -> done\n",
            "[419/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_01_oht01_0827_0330.zip\n",
            "  -> done\n",
            "[420/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_01_oht01_0827_0556.zip\n",
            "  -> done\n",
            "[421/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_01_oht01_0827_0901.zip\n",
            "  -> done\n",
            "[422/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_01_oht01_0901_1205.zip\n",
            "  -> done\n",
            "[423/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_01_oht01_0902_1338.zip\n",
            "  -> done\n",
            "[424/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_01_oht01_0906_0330.zip\n",
            "  -> done\n",
            "[425/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_01_oht01_0920_0734.zip\n",
            "  -> done\n",
            "[426/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_01_oht01_0920_1518.zip\n",
            "  -> done\n",
            "[427/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_01_oht01_0920_1912.zip\n",
            "  -> done\n",
            "[428/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_01_oht01_0920_2042.zip\n",
            "  -> done\n",
            "[429/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_02_oht02_0826_2038.zip\n",
            "  -> done\n",
            "[430/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_02_oht02_0827_0101.zip\n",
            "  -> done\n",
            "[431/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_02_oht02_0827_0343.zip\n",
            "  -> done\n",
            "[432/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_02_oht02_0827_0558.zip\n",
            "  -> done\n",
            "[433/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_02_oht02_0827_0910.zip\n",
            "  -> done\n",
            "[434/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_02_oht02_0901_1218.zip\n",
            "  -> done\n",
            "[435/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_02_oht02_0902_1345.zip\n",
            "  -> done\n",
            "[436/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_02_oht02_0906_0756.zip\n",
            "  -> done\n",
            "[437/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_02_oht02_0920_0746.zip\n",
            "  -> done\n",
            "[438/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_02_oht02_0920_1020.zip\n",
            "  -> done\n",
            "[439/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_02_oht02_0920_1623.zip\n",
            "  -> done\n",
            "[440/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_02_oht02_0920_2055.zip\n",
            "  -> done\n",
            "[441/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_03_oht03_0826_2049.zip\n",
            "  -> done\n",
            "[442/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_03_oht03_0826_2151.zip\n",
            "  -> done\n",
            "[443/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_03_oht03_0827_0109.zip\n",
            "  -> done\n",
            "[444/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_03_oht03_0827_0353.zip\n",
            "  -> done\n",
            "[445/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_03_oht03_0827_0605.zip\n",
            "  -> done\n",
            "[446/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_03_oht03_0827_0920.zip\n",
            "  -> done\n",
            "[447/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_03_oht03_0901_1227.zip\n",
            "  -> done\n",
            "[448/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_03_oht03_0902_1357.zip\n",
            "  -> done\n",
            "[449/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_03_oht03_0910_0841.zip\n",
            "  -> done\n",
            "[450/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_03_oht03_0920_0800.zip\n",
            "  -> done\n",
            "[451/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_03_oht03_0920_1634.zip\n",
            "  -> done\n",
            "[452/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_03_oht03_0920_2106.zip\n",
            "  -> done\n",
            "[453/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_04_oht04_0826_2056.zip\n",
            "  -> done\n",
            "[454/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_04_oht04_0827_0119.zip\n",
            "  -> done\n",
            "[455/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_04_oht04_0827_0403.zip\n",
            "  -> done\n",
            "[456/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_04_oht04_0827_0608.zip\n",
            "  -> done\n",
            "[457/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_04_oht04_0827_0947.zip\n",
            "  -> done\n",
            "[458/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_04_oht04_0901_1245.zip\n",
            "  -> done\n",
            "[459/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_04_oht04_0902_1415.zip\n",
            "  -> done\n",
            "[460/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_04_oht04_0911_0556.zip\n",
            "  -> done\n",
            "[461/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_04_oht04_0920_0811.zip\n",
            "  -> done\n",
            "[462/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_04_oht04_0920_1644.zip\n",
            "  -> done\n",
            "[463/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_04_oht04_0920_2118.zip\n",
            "  -> done\n",
            "[464/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_05_oht05_0826_1611.zip\n",
            "  -> done\n",
            "[465/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_05_oht05_0826_2059.zip\n",
            "  -> done\n",
            "[466/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_05_oht05_0827_0129.zip\n",
            "  -> done\n",
            "[467/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_05_oht05_0827_0405.zip\n",
            "  -> done\n",
            "[468/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_05_oht05_0827_0618.zip\n",
            "  -> done\n",
            "[469/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_05_oht05_0827_0846.zip\n",
            "  -> done\n",
            "[470/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_05_oht05_0827_0958.zip\n",
            "  -> done\n",
            "[471/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_05_oht05_0901_1252.zip\n",
            "  -> done\n",
            "[472/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_05_oht05_0902_1424.zip\n",
            "  -> done\n",
            "[473/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_05_oht05_0914_0632.zip\n",
            "  -> done\n",
            "[474/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_05_oht05_0920_0824.zip\n",
            "  -> done\n",
            "[475/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_05_oht05_0920_1654.zip\n",
            "  -> done\n",
            "[476/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_06_oht06_0826_1944.zip\n",
            "  -> done\n",
            "[477/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_06_oht06_0826_2243.zip\n",
            "  -> done\n",
            "[478/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_06_oht06_0827_0238.zip\n",
            "  -> done\n",
            "[479/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_06_oht06_0827_0514.zip\n",
            "  -> done\n",
            "[480/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_06_oht06_0827_0814.zip\n",
            "  -> done\n",
            "[481/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_06_oht06_0827_0859.zip\n",
            "  -> done\n",
            "[482/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_06_oht06_0901_1238.zip\n",
            "  -> done\n",
            "[483/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_06_oht06_0901_1310.zip\n",
            "  -> done\n",
            "[484/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_06_oht06_0903_0615.zip\n",
            "  -> done\n",
            "[485/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_06_oht06_0920_0448.zip\n",
            "  -> done\n",
            "[486/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_06_oht06_0920_1010.zip\n",
            "  -> done\n",
            "[487/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_06_oht06_0920_1922.zip\n",
            "  -> done\n",
            "[488/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_07_oht07_0826_1955.zip\n",
            "  -> done\n",
            "[489/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_07_oht07_0826_2253.zip\n",
            "  -> done\n",
            "[490/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_07_oht07_0827_0245.zip\n",
            "  -> done\n",
            "[491/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_07_oht07_0827_0515.zip\n",
            "  -> done\n",
            "[492/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_07_oht07_0827_0822.zip\n",
            "  -> done\n",
            "[493/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_07_oht07_0828_0728.zip\n",
            "  -> done\n",
            "[494/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_07_oht07_0901_1302.zip\n",
            "  -> done\n",
            "[495/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_07_oht07_0901_1316.zip\n",
            "  -> done\n",
            "[496/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_07_oht07_0903_0708.zip\n",
            "  -> done\n",
            "[497/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_07_oht07_0920_0502.zip\n",
            "  -> done\n",
            "[498/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_07_oht07_0920_1030.zip\n",
            "  -> done\n",
            "[499/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_07_oht07_0920_1932.zip\n",
            "  -> done\n",
            "[500/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_08_oht08_0826_2006.zip\n",
            "  -> done\n",
            "[501/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_08_oht08_0826_2332.zip\n",
            "  -> done\n",
            "[502/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_08_oht08_0827_0250.zip\n",
            "  -> done\n",
            "[503/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_08_oht08_0827_0525.zip\n",
            "  -> done\n",
            "[504/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_08_oht08_0827_0823.zip\n",
            "  -> done\n",
            "[505/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_08_oht08_0830_0223.zip\n",
            "  -> done\n",
            "[506/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_08_oht08_0901_1322.zip\n",
            "  -> done\n",
            "[507/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_08_oht08_0901_1416.zip\n",
            "  -> done\n",
            "[508/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_08_oht08_0903_0910.zip\n",
            "  -> done\n",
            "[509/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_08_oht08_0920_0516.zip\n",
            "  -> done\n",
            "[510/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_08_oht08_0920_1041.zip\n",
            "  -> done\n",
            "[511/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_08_oht08_0920_1942.zip\n",
            "  -> done\n",
            "[512/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_09_oht09_0826_2016.zip\n",
            "  -> done\n",
            "[513/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_09_oht09_0827_0001.zip\n",
            "  -> done\n",
            "[514/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_09_oht09_0827_0301.zip\n",
            "  -> done\n",
            "[515/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_09_oht09_0827_0535.zip\n",
            "  -> done\n",
            "[516/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_09_oht09_0827_0830.zip\n",
            "  -> done\n",
            "[517/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_09_oht09_0901_1331.zip\n",
            "  -> done\n",
            "[518/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_09_oht09_0902_1230.zip\n",
            "  -> done\n",
            "[519/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_09_oht09_0904_0405.zip\n",
            "  -> done\n",
            "[520/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_09_oht09_0906_0256.zip\n",
            "  -> done\n",
            "[521/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_09_oht09_0920_0642.zip\n",
            "  -> done\n",
            "[522/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_09_oht09_0920_1051.zip\n",
            "  -> done\n",
            "[523/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_09_oht09_0920_1952.zip\n",
            "  -> done\n",
            "[524/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_10_oht10_0826_2027.zip\n",
            "  -> done\n",
            "[525/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_10_oht10_0827_0021.zip\n",
            "  -> done\n",
            "[526/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_10_oht10_0827_0306.zip\n",
            "  -> done\n",
            "[527/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_10_oht10_0827_0545.zip\n",
            "  -> done\n",
            "[528/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_10_oht10_0827_0835.zip\n",
            "  -> done\n",
            "[529/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_10_oht10_0901_1337.zip\n",
            "  -> done\n",
            "[530/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_10_oht10_0902_1404.zip\n",
            "  -> done\n",
            "[531/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_10_oht10_0905_0535.zip\n",
            "  -> done\n",
            "[532/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_10_oht10_0920_0307.zip\n",
            "  -> done\n",
            "[533/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_10_oht10_0920_0654.zip\n",
            "  -> done\n",
            "[534/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_10_oht10_0920_1415.zip\n",
            "  -> done\n",
            "[535/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_10_oht10_0920_2003.zip\n",
            "  -> done\n",
            "[536/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_11_oht11_0826_2029.zip\n",
            "  -> done\n",
            "[537/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_11_oht11_0827_0031.zip\n",
            "  -> done\n",
            "[538/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_11_oht11_0827_0318.zip\n",
            "  -> done\n",
            "[539/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_11_oht11_0827_0546.zip\n",
            "  -> done\n",
            "[540/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_11_oht11_0827_0841.zip\n",
            "  -> done\n",
            "[541/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_11_oht11_0901_1344.zip\n",
            "  -> done\n",
            "[542/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_11_oht11_0906_0306.zip\n",
            "  -> done\n",
            "[543/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_11_oht11_0920_0706.zip\n",
            "  -> done\n",
            "[544/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_11_oht11_0920_0719.zip\n",
            "  -> done\n",
            "[545/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_11_oht11_0920_1439.zip\n",
            "  -> done\n",
            "[546/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_11_oht11_0920_2029.zip\n",
            "  -> done\n",
            "[547/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_11_oht11_1024_1025.zip\n",
            "  -> done\n",
            "[548/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_12_oht12_0826_1352.zip\n",
            "  -> done\n",
            "[549/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_12_oht12_0826_1625.zip\n",
            "  -> done\n",
            "[550/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_12_oht12_0826_2106.zip\n",
            "  -> done\n",
            "[551/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_12_oht12_0826_2130.zip\n",
            "  -> done\n",
            "[552/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_12_oht12_0827_0139.zip\n",
            "  -> done\n",
            "[553/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_12_oht12_0827_0414.zip\n",
            "  -> done\n",
            "[554/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_12_oht12_0827_0623.zip\n",
            "  -> done\n",
            "[555/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_12_oht12_0828_0420.zip\n",
            "  -> done\n",
            "[556/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_12_oht12_0901_1353.zip\n",
            "  -> done\n",
            "[557/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_12_oht12_0920_0242.zip\n",
            "  -> done\n",
            "[558/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_12_oht12_0920_0835.zip\n",
            "  -> done\n",
            "[559/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_12_oht12_0920_1704.zip\n",
            "  -> done\n",
            "[560/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_13_oht13_0826_1404.zip\n",
            "  -> done\n",
            "[561/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_13_oht13_0826_1751.zip\n",
            "  -> done\n",
            "[562/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_13_oht13_0826_2109.zip\n",
            "  -> done\n",
            "[563/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_13_oht13_0826_2140.zip\n",
            "  -> done\n",
            "[564/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_13_oht13_0827_0148.zip\n",
            "  -> done\n",
            "[565/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_13_oht13_0827_0420.zip\n",
            "  -> done\n",
            "[566/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_13_oht13_0827_0641.zip\n",
            "  -> done\n",
            "[567/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_13_oht13_0828_0947.zip\n",
            "  -> done\n",
            "[568/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_13_oht13_0901_1403.zip\n",
            "  -> done\n",
            "[569/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_13_oht13_0920_0254.zip\n",
            "  -> done\n",
            "[570/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_13_oht13_0920_0846.zip\n",
            "  -> done\n",
            "[571/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_13_oht13_0920_1714.zip\n",
            "  -> done\n",
            "[572/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_14_oht14_0826_1416.zip\n",
            "  -> done\n",
            "[573/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_14_oht14_0826_1803.zip\n",
            "  -> done\n",
            "[574/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_14_oht14_0826_2119.zip\n",
            "  -> done\n",
            "[575/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_14_oht14_0826_2234.zip\n",
            "  -> done\n",
            "[576/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_14_oht14_0827_0158.zip\n",
            "  -> done\n",
            "[577/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_14_oht14_0827_0424.zip\n",
            "  -> done\n",
            "[578/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_14_oht14_0827_0652.zip\n",
            "  -> done\n",
            "[579/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_14_oht14_0829_0525.zip\n",
            "  -> done\n",
            "[580/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_14_oht14_0901_1426.zip\n",
            "  -> done\n",
            "[581/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_14_oht14_0920_0319.zip\n",
            "  -> done\n",
            "[582/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_14_oht14_0920_0856.zip\n",
            "  -> done\n",
            "[583/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_14_oht14_0920_1724.zip\n",
            "  -> done\n",
            "[584/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_15_oht15_0826_1429.zip\n",
            "  -> done\n",
            "[585/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_15_oht15_0826_1816.zip\n",
            "  -> done\n",
            "[586/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_15_oht15_0826_2126.zip\n",
            "  -> done\n",
            "[587/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_15_oht15_0826_2312.zip\n",
            "  -> done\n",
            "[588/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_15_oht15_0827_0200.zip\n",
            "  -> done\n",
            "[589/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_15_oht15_0827_0431.zip\n",
            "  -> done\n",
            "[590/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_15_oht15_0827_0708.zip\n",
            "  -> done\n",
            "[591/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_15_oht15_0829_0605.zip\n",
            "  -> done\n",
            "[592/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_15_oht15_0901_1437.zip\n",
            "  -> done\n",
            "[593/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_15_oht15_0920_0332.zip\n",
            "  -> done\n",
            "[594/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_15_oht15_0920_0907.zip\n",
            "  -> done\n",
            "[595/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_15_oht15_0920_1745.zip\n",
            "  -> done\n",
            "[596/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_16_oht16_0826_1441.zip\n",
            "  -> done\n",
            "[597/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_16_oht16_0826_1829.zip\n",
            "  -> done\n",
            "[598/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_16_oht16_0826_2137.zip\n",
            "  -> done\n",
            "[599/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_16_oht16_0827_0208.zip\n",
            "  -> done\n",
            "[600/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_16_oht16_0827_0219.zip\n",
            "  -> done\n",
            "[601/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_16_oht16_0827_0434.zip\n",
            "  -> done\n",
            "[602/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_16_oht16_0827_0713.zip\n",
            "  -> done\n",
            "[603/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_16_oht16_0830_0658.zip\n",
            "  -> done\n",
            "[604/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_16_oht16_0902_1241.zip\n",
            "  -> done\n",
            "[605/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_16_oht16_0920_0344.zip\n",
            "  -> done\n",
            "[606/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_16_oht16_0920_0917.zip\n",
            "  -> done\n",
            "[607/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_oht_16_oht16_0920_1756.zip\n",
            "  -> done\n",
            "[608/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/01.원천데이터/VS_agv_17_agv17_0902_1039.zip\n",
            "  -> done\n",
            "[609/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/01.원천데이터/VS_agv_17_agv17_0902_1908.zip\n",
            "  -> done\n",
            "[610/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/01.원천데이터/VS_agv_17_agv17_0903_0732.zip\n",
            "  -> done\n",
            "[611/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/01.원천데이터/VS_agv_17_agv17_0903_1328.zip\n",
            "  -> done\n",
            "[612/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/01.원천데이터/VS_agv_17_agv17_1026_2338.zip\n",
            "  -> done\n",
            "[613/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/01.원천데이터/VS_agv_17_agv17_1027_1314.zip\n",
            "  -> done\n",
            "[614/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/01.원천데이터/VS_agv_17_agv17_1027_1345.zip\n",
            "  -> done\n",
            "[615/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/01.원천데이터/VS_agv_18_agv18_0902_1050.zip\n",
            "  -> done\n",
            "[616/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/01.원천데이터/VS_agv_18_agv18_0902_1929.zip\n",
            "  -> done\n",
            "[617/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/01.원천데이터/VS_agv_18_agv18_0903_0804.zip\n",
            "  -> done\n",
            "[618/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/01.원천데이터/VS_agv_18_agv18_0903_1337.zip\n",
            "  -> done\n",
            "[619/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/01.원천데이터/VS_agv_18_agv18_1026_2356.zip\n",
            "  -> done\n",
            "[620/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/01.원천데이터/VS_agv_18_agv18_1027_1324.zip\n",
            "  -> done\n",
            "[621/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/01.원천데이터/VS_agv_18_agv18_1027_1416.zip\n",
            "  -> done\n",
            "[622/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/01.원천데이터/VS_oht_17_oht17_0826_1454.zip\n",
            "  -> done\n",
            "[623/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/01.원천데이터/VS_oht_17_oht17_0826_1843.zip\n",
            "  -> done\n",
            "[624/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/01.원천데이터/VS_oht_17_oht17_0826_2146.zip\n",
            "  -> done\n",
            "[625/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/01.원천데이터/VS_oht_17_oht17_0827_0215.zip\n",
            "  -> done\n",
            "[626/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/01.원천데이터/VS_oht_17_oht17_0827_0223.zip\n",
            "  -> done\n",
            "[627/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/01.원천데이터/VS_oht_17_oht17_0827_0444.zip\n",
            "  -> done\n",
            "[628/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/01.원천데이터/VS_oht_17_oht17_0827_0723.zip\n",
            "  -> done\n",
            "[629/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/01.원천데이터/VS_oht_17_oht17_0830_0814.zip\n",
            "  -> done\n",
            "[630/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/01.원천데이터/VS_oht_17_oht17_0902_1252.zip\n",
            "  -> done\n",
            "[631/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/01.원천데이터/VS_oht_17_oht17_0920_0359.zip\n",
            "  -> done\n",
            "[632/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/01.원천데이터/VS_oht_17_oht17_0920_0928.zip\n",
            "  -> done\n",
            "[633/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/01.원천데이터/VS_oht_17_oht17_0920_1817.zip\n",
            "  -> done\n",
            "[634/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/01.원천데이터/VS_oht_18_oht18_0826_1521.zip\n",
            "  -> done\n",
            "[635/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/01.원천데이터/VS_oht_18_oht18_0826_1856.zip\n",
            "  -> done\n",
            "[636/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/01.원천데이터/VS_oht_18_oht18_0826_2155.zip\n",
            "  -> done\n",
            "[637/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/01.원천데이터/VS_oht_18_oht18_0827_0227.zip\n",
            "  -> done\n",
            "[638/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/01.원천데이터/VS_oht_18_oht18_0827_0256.zip\n",
            "  -> done\n",
            "[639/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/01.원천데이터/VS_oht_18_oht18_0827_0454.zip\n",
            "  -> done\n",
            "[640/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/01.원천데이터/VS_oht_18_oht18_0827_0743.zip\n",
            "  -> done\n",
            "[641/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/01.원천데이터/VS_oht_18_oht18_0902_0245.zip\n",
            "  -> done\n",
            "[642/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/01.원천데이터/VS_oht_18_oht18_0902_1304.zip\n",
            "  -> done\n",
            "[643/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/01.원천데이터/VS_oht_18_oht18_0920_0412.zip\n",
            "  -> done\n",
            "[644/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/01.원천데이터/VS_oht_18_oht18_0920_0939.zip\n",
            "  -> done\n",
            "[645/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/01.원천데이터/VS_oht_18_oht18_0920_1828.zip\n",
            "  -> done\n",
            "[646/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/02.라벨링데이터/VL_agv_17_agv17_0902_1039.zip\n",
            "  -> done\n",
            "[647/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/02.라벨링데이터/VL_agv_17_agv17_0902_1908.zip\n",
            "  -> done\n",
            "[648/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/02.라벨링데이터/VL_agv_17_agv17_0903_0732.zip\n",
            "  -> done\n",
            "[649/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/02.라벨링데이터/VL_agv_17_agv17_0903_1328.zip\n",
            "  -> done\n",
            "[650/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/02.라벨링데이터/VL_agv_17_agv17_1026_2338.zip\n",
            "  -> done\n",
            "[651/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/02.라벨링데이터/VL_agv_17_agv17_1027_1314.zip\n",
            "  -> done\n",
            "[652/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/02.라벨링데이터/VL_agv_17_agv17_1027_1345.zip\n",
            "  -> done\n",
            "[653/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/02.라벨링데이터/VL_agv_18_agv18_0902_1050.zip\n",
            "  -> done\n",
            "[654/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/02.라벨링데이터/VL_agv_18_agv18_0902_1929.zip\n",
            "  -> done\n",
            "[655/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/02.라벨링데이터/VL_agv_18_agv18_0903_0804.zip\n",
            "  -> done\n",
            "[656/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/02.라벨링데이터/VL_agv_18_agv18_0903_1337.zip\n",
            "  -> done\n",
            "[657/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/02.라벨링데이터/VL_agv_18_agv18_1026_2356.zip\n",
            "  -> done\n",
            "[658/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/02.라벨링데이터/VL_agv_18_agv18_1027_1324.zip\n",
            "  -> done\n",
            "[659/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/02.라벨링데이터/VL_agv_18_agv18_1027_1416.zip\n",
            "  -> done\n",
            "[660/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/02.라벨링데이터/VL_oht_17_oht17_0826_1454.zip\n",
            "  -> done\n",
            "[661/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/02.라벨링데이터/VL_oht_17_oht17_0826_1843.zip\n",
            "  -> done\n",
            "[662/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/02.라벨링데이터/VL_oht_17_oht17_0826_2146.zip\n",
            "  -> done\n",
            "[663/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/02.라벨링데이터/VL_oht_17_oht17_0827_0215.zip\n",
            "  -> done\n",
            "[664/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/02.라벨링데이터/VL_oht_17_oht17_0827_0223.zip\n",
            "  -> done\n",
            "[665/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/02.라벨링데이터/VL_oht_17_oht17_0827_0444.zip\n",
            "  -> done\n",
            "[666/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/02.라벨링데이터/VL_oht_17_oht17_0827_0723.zip\n",
            "  -> done\n",
            "[667/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/02.라벨링데이터/VL_oht_17_oht17_0830_0814.zip\n",
            "  -> done\n",
            "[668/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/02.라벨링데이터/VL_oht_17_oht17_0902_1252.zip\n",
            "  -> done\n",
            "[669/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/02.라벨링데이터/VL_oht_17_oht17_0920_0359.zip\n",
            "  -> done\n",
            "[670/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/02.라벨링데이터/VL_oht_17_oht17_0920_0928.zip\n",
            "  -> done\n",
            "[671/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/02.라벨링데이터/VL_oht_17_oht17_0920_1817.zip\n",
            "  -> done\n",
            "[672/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/02.라벨링데이터/VL_oht_18_oht18_0826_1521.zip\n",
            "  -> done\n",
            "[673/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/02.라벨링데이터/VL_oht_18_oht18_0826_1856.zip\n",
            "  -> done\n",
            "[674/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/02.라벨링데이터/VL_oht_18_oht18_0826_2155.zip\n",
            "  -> done\n",
            "[675/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/02.라벨링데이터/VL_oht_18_oht18_0827_0227.zip\n",
            "  -> done\n",
            "[676/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/02.라벨링데이터/VL_oht_18_oht18_0827_0256.zip\n",
            "  -> done\n",
            "[677/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/02.라벨링데이터/VL_oht_18_oht18_0827_0454.zip\n",
            "  -> done\n",
            "[678/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/02.라벨링데이터/VL_oht_18_oht18_0827_0743.zip\n",
            "  -> done\n",
            "[679/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/02.라벨링데이터/VL_oht_18_oht18_0902_0245.zip\n",
            "  -> done\n",
            "[680/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/02.라벨링데이터/VL_oht_18_oht18_0902_1304.zip\n",
            "  -> done\n",
            "[681/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/02.라벨링데이터/VL_oht_18_oht18_0920_0412.zip\n",
            "  -> done\n",
            "[682/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/02.라벨링데이터/VL_oht_18_oht18_0920_0939.zip\n",
            "  -> done\n",
            "[683/683] unzip: /content/drive/MyDrive/3.개방데이터/1.데이터/Validation/02.라벨링데이터/VL_oht_18_oht18_0920_1828.zip\n",
            "  -> done\n",
            "[INFO] BASE_DIR: /content/data_71802_local/extracted\n",
            "[INFO] extracted counts: {'csv': 236133, 'bin': 111870, 'json': 111870, 'zip': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2) complete_keys 없으면 자동 생성 → episodes/samples까지 한 번에"
      ],
      "metadata": {
        "id": "Y00BABfPa5y7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import re\n",
        "from collections import defaultdict\n",
        "\n",
        "# ✅ BASE_DIR 확인(압축 풀린 루트)\n",
        "BASE_DIR = Path(\"/content/data_71802_local/extracted\")\n",
        "\n",
        "# --- records + complete_keys 자동 생성 ---\n",
        "stem_pat = re.compile(r\"^(?P<prefix>[a-zA-Z]+)(?P<id>\\d+)_(?P<mmdd>\\d{4})_(?P<hms>\\d{6})$\")\n",
        "\n",
        "def build_records_by_stem(base_dir: Path):\n",
        "    records = defaultdict(dict)\n",
        "    for f in base_dir.rglob(\"*\"):\n",
        "        if not f.is_file():\n",
        "            continue\n",
        "        ext = f.suffix.lower().lstrip(\".\")\n",
        "        if ext not in (\"csv\",\"bin\",\"json\"):\n",
        "            continue\n",
        "        m = stem_pat.match(f.stem)\n",
        "        if not m:\n",
        "            continue\n",
        "        g = m.groupdict()\n",
        "        key = (g[\"prefix\"].lower(), int(g[\"id\"]), g[\"mmdd\"], g[\"hms\"])\n",
        "        records[key][ext] = str(f)\n",
        "\n",
        "    records = dict(records)\n",
        "    complete_keys = [k for k,v in records.items() if all(x in v for x in (\"csv\",\"bin\",\"json\"))]\n",
        "    print(\"records:\", len(records))\n",
        "    print(\"complete_keys:\", len(complete_keys))\n",
        "    return records, complete_keys\n",
        "\n",
        "# complete_keys가 없으면 생성\n",
        "if \"complete_keys\" not in globals() or \"records\" not in globals():\n",
        "    records, complete_keys = build_records_by_stem(BASE_DIR)\n",
        "\n",
        "# --- episodes / samples 생성 ---\n",
        "PAST = 30\n",
        "HORIZON = 30\n",
        "\n",
        "def build_episodes(keys):\n",
        "    epi_map = defaultdict(list)\n",
        "    for (prefix, did, mmdd, hms) in keys:\n",
        "        epi_map[(prefix, did, mmdd)].append((prefix, did, mmdd, hms))\n",
        "    episodes=[]\n",
        "    for epi_id, ks in epi_map.items():\n",
        "        episodes.append((epi_id, sorted(ks, key=lambda x: x[3])))\n",
        "    return episodes\n",
        "\n",
        "episodes = build_episodes(complete_keys)\n",
        "print(\"episodes:\", len(episodes))\n",
        "\n",
        "def build_samples(episodes, past=PAST, horizon=HORIZON):\n",
        "    samples=[]\n",
        "    for epi_idx, (_, ks) in enumerate(episodes):\n",
        "        L = len(ks)\n",
        "        for t in range(past-1, L-horizon):\n",
        "            samples.append((epi_idx, t))\n",
        "    return samples\n",
        "\n",
        "samples = build_samples(episodes)\n",
        "print(\"samples:\", len(samples))\n",
        "\n",
        "# (검증) 에피소드 길이 분포 조금 보기\n",
        "lens = [len(ks) for _, ks in episodes]\n",
        "print(\"episode length min/mean/max:\", min(lens), sum(lens)/len(lens), max(lens))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9xn9nyS7e_G",
        "outputId": "d7d81edb-3eba-4d43-a79c-f12314c83802"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "records: 124263\n",
            "complete_keys: 111870\n",
            "episodes: 185\n",
            "samples: 100955\n",
            "episode length min/mean/max: 300 604.7027027027027 1504\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3) 센서/라벨 로더 + valid 필터링(라벨 None 제거)"
      ],
      "metadata": {
        "id": "KUlTWHDnbOKC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, pandas as pd, csv, json\n",
        "from pathlib import Path\n",
        "\n",
        "SENSOR8 = [\"PM1.0\",\"PM2.5\",\"PM10\",\"NTC\",\"CT1\",\"CT2\",\"CT3\",\"CT4\"]\n",
        "\n",
        "def load_sensor_csv(path: str) -> np.ndarray:\n",
        "    raw = Path(path).read_text(encoding=\"utf-8\", errors=\"replace\")\n",
        "    lines = [ln.strip().lstrip(\"\\ufeff\") for ln in raw.splitlines() if ln.strip()]\n",
        "\n",
        "    # (A) 메타 로그형\n",
        "    if any(ln.startswith(\"sensor_data,\") for ln in lines[:80]):\n",
        "        vals = {k: None for k in SENSOR8}\n",
        "        for ln in lines:\n",
        "            parts = [p.strip().strip('\"') for p in ln.split(\",\")]\n",
        "            if len(parts) >= 4 and parts[0] == \"sensor_data\":\n",
        "                name, field = parts[1], parts[2]\n",
        "                if name in vals and field == \"value\":\n",
        "                    try: vals[name] = float(parts[3])\n",
        "                    except: pass\n",
        "        if any(vals[k] is None for k in SENSOR8):\n",
        "            raise ValueError(f\"Missing sensor values in {path}\")\n",
        "        return np.array([vals[k] for k in SENSOR8], dtype=np.float32)\n",
        "\n",
        "    # (B) TS 테이블형\n",
        "    try:\n",
        "        dialect = csv.Sniffer().sniff(raw[:2048], delimiters=[\",\",\";\",\"\\t\",\"|\"])\n",
        "        sep = dialect.delimiter\n",
        "    except:\n",
        "        sep = \",\"\n",
        "    df = pd.read_csv(path, sep=sep, engine=\"python\", on_bad_lines=\"skip\")\n",
        "    df.columns = [str(c).strip() for c in df.columns]\n",
        "    if set(SENSOR8).issubset(set(df.columns)):\n",
        "        return df.iloc[-1][SENSOR8].astype(np.float32).to_numpy()\n",
        "\n",
        "    num_df = df.select_dtypes(include=[\"number\"])\n",
        "    if num_df.shape[1] >= 8:\n",
        "        return num_df.iloc[-1, :8].astype(np.float32).to_numpy()\n",
        "    raise ValueError(f\"Cannot parse sensor csv: {path}\")\n",
        "\n",
        "LABEL_KEYS = [\"label\",\"Label\",\"state\",\"State\",\"status\",\"Status\",\"target\",\"Target\",\"class\",\"Class\",\"y\",\"Y\"]\n",
        "\n",
        "def _find_first_int_like(obj):\n",
        "    if isinstance(obj, dict):\n",
        "        for k,v in obj.items():\n",
        "            if isinstance(k, str) and any(x in k.lower() for x in [\"label\",\"state\",\"status\",\"class\",\"target\"]):\n",
        "                out = _find_first_int_like(v)\n",
        "                if out is not None: return out\n",
        "            out = _find_first_int_like(v)\n",
        "            if out is not None: return out\n",
        "    elif isinstance(obj, list):\n",
        "        for it in obj:\n",
        "            out = _find_first_int_like(it)\n",
        "            if out is not None: return out\n",
        "    else:\n",
        "        try:\n",
        "            val = int(float(obj))\n",
        "            if 0 <= val <= 3: return val\n",
        "        except:\n",
        "            return None\n",
        "    return None\n",
        "\n",
        "def load_label_json(path: str):\n",
        "    try:\n",
        "        d = json.loads(Path(path).read_text(encoding=\"utf-8\", errors=\"replace\"))\n",
        "    except:\n",
        "        return None\n",
        "    if isinstance(d, dict):\n",
        "        for k in LABEL_KEYS:\n",
        "            if k in d:\n",
        "                v = _find_first_int_like(d[k])\n",
        "                if v is not None: return v\n",
        "    return _find_first_int_like(d)\n",
        "\n",
        "# --- valid filtering ---\n",
        "samples_valid=[]\n",
        "for epi_idx, t in samples:\n",
        "    _, ks = episodes[epi_idx]\n",
        "    yk = ks[t+HORIZON]\n",
        "    y = load_label_json(records[yk][\"json\"])\n",
        "    if y is not None:\n",
        "        samples_valid.append((epi_idx,t))\n",
        "\n",
        "print(\"samples_valid:\", len(samples_valid))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_z56iRSiGR7j",
        "outputId": "b27df912-8857-4aff-bfa7-14cb221cd9f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "samples_valid: 100955\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "\n",
        "def split_by_episode(samples_valid, ratios=(0.8,0.1,0.1), seed=SEED):\n",
        "    random.seed(seed)\n",
        "    epi_to = defaultdict(list)\n",
        "    for e,t in samples_valid:\n",
        "        epi_to[e].append((e,t))\n",
        "    epi_ids = list(epi_to.keys())\n",
        "    random.shuffle(epi_ids)\n",
        "    n=len(epi_ids)\n",
        "    n_tr=int(n*ratios[0]); n_va=int(n*ratios[1])\n",
        "    tr=set(epi_ids[:n_tr]); va=set(epi_ids[n_tr:n_tr+n_va]); te=set(epi_ids[n_tr+n_va:])\n",
        "    train=[s for e in tr for s in epi_to[e]]\n",
        "    val  =[s for e in va for s in epi_to[e]]\n",
        "    test =[s for e in te for s in epi_to[e]]\n",
        "    return train,val,test,(len(tr),len(va),len(te))\n",
        "\n",
        "train_s, val_s, test_s, epi_counts = split_by_episode(samples_valid)\n",
        "print(\"episode split:\", epi_counts)\n",
        "print(\"sample split :\", len(train_s), len(val_s), len(test_s))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZOEP7uzGuYV",
        "outputId": "5c596bd7-1ad8-4546-e78f-a81a1536ecc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "episode split: (148, 18, 19)\n",
            "sample split : 80153 9469 11333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5) 열화상 캐시(속도) — 먼저 10,000개만"
      ],
      "metadata": {
        "id": "oendof8VbWNI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "CACHE_DIR = Path(\"/content/cache_thermal_celsius\")\n",
        "CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "H, W = 120, 160\n",
        "NPIX = H*W\n",
        "\n",
        "def _score_kelvin_like(x):\n",
        "    finite = np.isfinite(x)\n",
        "    if finite.mean() < 0.98: return -1e9\n",
        "    xf = x[finite]\n",
        "    mu, sd = float(xf.mean()), float(xf.std())\n",
        "    score = 0.0\n",
        "    if 150 <= mu <= 450: score += 100\n",
        "    score -= abs(mu - 300) * 0.2\n",
        "    if sd > 250: score -= (sd - 250) * 2\n",
        "    return score\n",
        "\n",
        "def decode_thermal_bin(path: str) -> np.ndarray:\n",
        "    b = Path(path).read_bytes()\n",
        "    need = NPIX * 2\n",
        "    tail = b[-need:]\n",
        "    cands=[]\n",
        "    specs=[(np.uint16,False),(np.uint16,True),(np.int16,False),(np.int16,True)]\n",
        "    scales=[1.0,0.1,0.01]\n",
        "    for dt, swap in specs:\n",
        "        arr = np.frombuffer(tail, dtype=dt)\n",
        "        if swap: arr = arr.byteswap()\n",
        "        x = arr.reshape(H,W).astype(np.float32)\n",
        "        for sc in scales:\n",
        "            cands.append(x*sc)\n",
        "    best_x, best_s=None, -1e9\n",
        "    for x in cands:\n",
        "        s=_score_kelvin_like(x)\n",
        "        if s>best_s: best_s, best_x=s, x\n",
        "    return best_x\n",
        "\n",
        "def thermal_preprocess(bin_path: str, invalid_k_le=1.0, clip_c=(-50.0,200.0)):\n",
        "    img = decode_thermal_bin(bin_path).astype(np.float32)\n",
        "    img = np.where(img <= invalid_k_le, np.nan, img)\n",
        "    img = img - 273.15\n",
        "    lo,hi = clip_c\n",
        "    img = np.where((img<lo)|(img>hi), np.nan, img)\n",
        "    m = np.nanmedian(img)\n",
        "    return np.nan_to_num(img, nan=float(m))\n",
        "\n",
        "def cache_one(bin_path: str) -> bool:\n",
        "    out = CACHE_DIR / (Path(bin_path).stem + \".npy\")\n",
        "    if out.exists(): return True\n",
        "    try:\n",
        "        np.save(out, thermal_preprocess(bin_path).astype(np.float32))\n",
        "        return True\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "def load_thermal_cached(bin_path: str) -> np.ndarray:\n",
        "    npy = CACHE_DIR / (Path(bin_path).stem + \".npy\")\n",
        "    if npy.exists(): return np.load(npy).astype(np.float32)\n",
        "    return thermal_preprocess(bin_path).astype(np.float32)\n",
        "\n",
        "def bins_from_samples(samples_list):\n",
        "    s=set()\n",
        "    for epi_idx,t in samples_list:\n",
        "        _, ks = episodes[epi_idx]\n",
        "        for dt in (29,14,0):\n",
        "            s.add(records[ks[t-dt]][\"bin\"])\n",
        "    return list(s)\n",
        "\n",
        "need_bins = list(set(bins_from_samples(train_s) + bins_from_samples(val_s)))\n",
        "print(\"need_bins:\", len(need_bins))\n",
        "\n",
        "ok=0\n",
        "for p in need_bins[:10000]:\n",
        "    ok += int(cache_one(p))\n",
        "print(\"cached:\", ok, \"/ 10000\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKEPXqNYHQMY",
        "outputId": "d5a92e76-3a07-47a6-a419-213bf62288d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "need_bins: 94436\n",
            "cached: 10000 / 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6) sensor mean/std(train only)"
      ],
      "metadata": {
        "id": "4bU9VA0LbY6o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_sensor_stats(train_s, max_rows=20000):\n",
        "    xs=[]\n",
        "    for i,(epi_idx,t) in enumerate(train_s):\n",
        "        if i>=max_rows: break\n",
        "        _, ks = episodes[epi_idx]\n",
        "        xs.append(load_sensor_csv(records[ks[t]][\"csv\"]))\n",
        "    X = np.stack(xs, axis=0).astype(np.float32)\n",
        "    return X.mean(axis=0), X.std(axis=0)+1e-6\n",
        "\n",
        "def zscore_clip_sensor(sw, mu, sd, clip=3.0):\n",
        "    z = (sw - mu)/sd\n",
        "    return np.clip(z, -clip, clip).astype(np.float32)\n",
        "\n",
        "sensor_mean, sensor_std = compute_sensor_stats(train_s)\n",
        "print(\"sensor_mean:\", sensor_mean)\n",
        "print(\"sensor_std :\", sensor_std)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFd8zHdoHbcF",
        "outputId": "2e581173-b2b6-4d42-9077-363d8c7683a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sensor_mean: [11.67935  16.089    27.73555  32.233047  6.949652 25.268726 14.244119\n",
            "  6.012115]\n",
            "sensor_std : [ 8.065869  9.157165 17.152046  8.07791  18.231245 34.726257 23.67867\n",
            " 13.208   ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#8) Dataset/DataLoader + 속도검증"
      ],
      "metadata": {
        "id": "NdqMo6l2bdV4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "IMG_SIZE = 224\n",
        "IMG_MEAN = 43.715\n",
        "IMG_STD  = 4.673\n",
        "\n",
        "def resize_img(img_120x160: np.ndarray, out=IMG_SIZE) -> np.ndarray:\n",
        "    x = torch.tensor(img_120x160[None,None,:,:], dtype=torch.float32)  # (1,1,120,160)\n",
        "    x = torch.nn.functional.interpolate(x, size=(out,out), mode=\"bilinear\", align_corners=False)\n",
        "    return x[0,0].numpy()\n",
        "\n",
        "class ForecastSingleDataset(Dataset):\n",
        "    def __init__(self, samples_list):\n",
        "        self.samples = samples_list\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        epi_idx, t = self.samples[idx]\n",
        "        _, ks = episodes[epi_idx]\n",
        "\n",
        "        # sensor window (30,8)\n",
        "        win_keys = ks[t-(PAST-1):t+1]\n",
        "        sw = np.stack([load_sensor_csv(records[k][\"csv\"]) for k in win_keys], axis=0).astype(np.float32)\n",
        "        sw = zscore_clip_sensor(sw, sensor_mean, sensor_std, clip=3.0)\n",
        "\n",
        "        # image stack (3,224,224): t-29, t-14, t\n",
        "        im1 = resize_img(load_thermal_cached(records[ks[t-29]][\"bin\"]))\n",
        "        im2 = resize_img(load_thermal_cached(records[ks[t-14]][\"bin\"]))\n",
        "        im3 = resize_img(load_thermal_cached(records[ks[t]][\"bin\"]))\n",
        "        img = np.stack([im1, im2, im3], axis=0).astype(np.float32)\n",
        "\n",
        "        # 논문 z-score (Celsius)\n",
        "        img = (img - IMG_MEAN) / (IMG_STD + 1e-8)\n",
        "\n",
        "        # target (t+30)\n",
        "        y = float(load_label_json(records[ks[t+HORIZON]][\"json\"]))  # samples_valid로 None 제거됨\n",
        "\n",
        "        return {\n",
        "            \"sensor_window\": torch.tensor(sw, dtype=torch.float32),\n",
        "            \"ir_images\": torch.tensor(img, dtype=torch.float32),\n",
        "            \"target\": torch.tensor(y, dtype=torch.float32),\n",
        "        }\n",
        "\n",
        "ds_train = ForecastSingleDataset(train_s)\n",
        "ds_val   = ForecastSingleDataset(val_s)\n",
        "ds_test  = ForecastSingleDataset(test_s)\n",
        "\n",
        "dl_train = DataLoader(ds_train, batch_size=32, shuffle=True,  num_workers=2, pin_memory=True)\n",
        "dl_val   = DataLoader(ds_val,   batch_size=32, shuffle=False, num_workers=2, pin_memory=True)\n",
        "dl_test  = DataLoader(ds_test,  batch_size=32, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "# ✅ 샘플 검증\n",
        "b = ds_train[0]\n",
        "print(\"sample check:\", b[\"sensor_window\"].shape, b[\"ir_images\"].shape, b[\"target\"].item())\n",
        "\n",
        "# ✅ 로딩 속도 검증\n",
        "t0 = time.time()\n",
        "for i, batch in enumerate(dl_train):\n",
        "    if i == 5:\n",
        "        break\n",
        "print(\"5 batches load time(sec):\", time.time() - t0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_31trx3H0-t",
        "outputId": "990f0586-308d-4484-fd2e-5c14521dd707"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample check: torch.Size([30, 8]) torch.Size([3, 224, 224]) 1.0\n",
            "5 batches load time(sec): 2.4176673889160156\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#9) MMT 모델 + 학습 루프(안전장치 포함: steps 로그)\n",
        "# ❌ 아래 코드 학습 잘못된거임!!! 맨 마지막 페이지 봐야함!!!"
      ],
      "metadata": {
        "id": "BU_MqXAkboGZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "class MMT(nn.Module):\n",
        "    def __init__(self, d_model=256, nhead=8, layers=4, patch=16):\n",
        "        super().__init__()\n",
        "        self.patch = patch\n",
        "        self.img_tokens = (IMG_SIZE // patch) * (IMG_SIZE // patch)  # 196\n",
        "\n",
        "        self.img_proj = nn.Linear(patch*patch*3, d_model)\n",
        "        self.sen_proj = nn.Linear(8, d_model)\n",
        "\n",
        "        self.cls = nn.Parameter(torch.zeros(1,1,d_model))\n",
        "        self.pos = nn.Parameter(torch.zeros(1,1+self.img_tokens+PAST, d_model))\n",
        "\n",
        "        enc = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, batch_first=True)\n",
        "        self.enc = nn.TransformerEncoder(enc, num_layers=layers)\n",
        "\n",
        "        self.head = nn.Linear(d_model, 1)\n",
        "        nn.init.trunc_normal_(self.cls, std=0.02)\n",
        "        nn.init.trunc_normal_(self.pos, std=0.02)\n",
        "\n",
        "    def img_to_tokens(self, x):\n",
        "        B,C,H,W = x.shape\n",
        "        p = self.patch\n",
        "        patches = x.unfold(2,p,p).unfold(3,p,p)          # (B,3,14,14,16,16)\n",
        "        patches = patches.permute(0,2,3,1,4,5).contiguous()\n",
        "        patches = patches.view(B, self.img_tokens, C*p*p) # (B,196,3*256)\n",
        "        return self.img_proj(patches)                     # (B,196,d)\n",
        "\n",
        "    def forward(self, sensor_window, ir_images):\n",
        "        B = sensor_window.size(0)\n",
        "        tok_img = self.img_to_tokens(ir_images)           # (B,196,d)\n",
        "        tok_sen = self.sen_proj(sensor_window)            # (B,30,d)\n",
        "\n",
        "        cls = self.cls.expand(B,-1,-1)                    # (B,1,d)\n",
        "        x = torch.cat([cls, tok_img, tok_sen], dim=1)     # (B,227,d)\n",
        "        x = x + self.pos[:, :x.size(1), :]\n",
        "        h = self.enc(x)\n",
        "        return self.head(h[:,0]).squeeze(1)               # (B,)\n",
        "\n",
        "def evaluate(model, loader, device):\n",
        "    model.eval()\n",
        "    loss_fn = nn.MSELoss()\n",
        "    losses=[]\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            sen = batch[\"sensor_window\"].to(device)\n",
        "            img = batch[\"ir_images\"].to(device)\n",
        "            y   = batch[\"target\"].to(device)\n",
        "            yhat = model(sen, img)\n",
        "            losses.append(loss_fn(yhat, y).item())\n",
        "    return float(np.mean(losses)) if losses else 1e9\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"device:\", device)\n",
        "\n",
        "model = MMT().to(device)\n",
        "opt = optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-2)\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "best = 1e9\n",
        "EPOCHS = 5\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    model.train()\n",
        "    run=0.0; n=0\n",
        "\n",
        "    for step, batch in enumerate(dl_train, 1):\n",
        "        sen = batch[\"sensor_window\"].to(device)\n",
        "        img = batch[\"ir_images\"].to(device)\n",
        "        y   = batch[\"target\"].to(device)\n",
        "\n",
        "        opt.zero_grad(set_to_none=True)\n",
        "        yhat = model(sen, img)\n",
        "        loss = loss_fn(yhat, y)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        opt.step()\n",
        "\n",
        "        run += loss.item() * sen.size(0)\n",
        "        n += sen.size(0)\n",
        "\n",
        "        # ✅ 진행 확인용(너가 불안해했던 부분 해결)\n",
        "        if step % 200 == 0:\n",
        "            print(f\"  step {step} | batch_loss {loss.item():.4f}\")\n",
        "\n",
        "    tr_loss = run/max(n,1)\n",
        "    va_loss = evaluate(model, dl_val, device)\n",
        "    print(f\"Epoch {epoch} | train {tr_loss:.4f} | val {va_loss:.4f}\")\n",
        "\n",
        "    if va_loss < best:\n",
        "        best = va_loss\n",
        "        torch.save(model.state_dict(), \"/content/mmt_best.pt\")\n",
        "        print(\"  saved best.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKHJ2PRKMJsd",
        "outputId": "ca3a33a4-13e8-489a-fcbb-5711e620485b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cuda\n",
            "  step 200 | batch_loss 0.0007\n",
            "  step 400 | batch_loss 0.0004\n",
            "  step 600 | batch_loss 0.0001\n",
            "  step 800 | batch_loss 0.0001\n",
            "  step 1000 | batch_loss 0.0004\n",
            "  step 1200 | batch_loss 0.0001\n",
            "  step 1400 | batch_loss 0.0003\n",
            "  step 1600 | batch_loss 0.0001\n",
            "  step 1800 | batch_loss 0.0001\n",
            "  step 2000 | batch_loss 0.0000\n",
            "  step 2200 | batch_loss 0.0001\n",
            "  step 2400 | batch_loss 0.0002\n",
            "Epoch 1 | train 0.0151 | val 0.0007\n",
            "  saved best.\n",
            "  step 200 | batch_loss 0.0000\n",
            "  step 400 | batch_loss 0.0000\n",
            "  step 600 | batch_loss 0.0000\n",
            "  step 800 | batch_loss 0.0000\n",
            "  step 1000 | batch_loss 0.0000\n",
            "  step 1200 | batch_loss 0.0001\n",
            "  step 1400 | batch_loss 0.0001\n",
            "  step 1600 | batch_loss 0.0001\n",
            "  step 1800 | batch_loss 0.0000\n",
            "  step 2000 | batch_loss 0.0000\n",
            "  step 2200 | batch_loss 0.0000\n",
            "  step 2400 | batch_loss 0.0001\n",
            "Epoch 2 | train 0.0001 | val 0.0012\n",
            "  step 200 | batch_loss 0.0000\n",
            "  step 400 | batch_loss 0.0002\n",
            "  step 600 | batch_loss 0.0000\n",
            "  step 800 | batch_loss 0.0001\n",
            "  step 1000 | batch_loss 0.0001\n",
            "  step 1200 | batch_loss 0.0001\n",
            "  step 1400 | batch_loss 0.0000\n",
            "  step 1600 | batch_loss 0.0000\n",
            "  step 1800 | batch_loss 0.0001\n",
            "  step 2000 | batch_loss 0.0000\n",
            "  step 2200 | batch_loss 0.0000\n",
            "  step 2400 | batch_loss 0.0000\n",
            "Epoch 3 | train 0.0000 | val 0.0011\n",
            "  step 200 | batch_loss 0.0000\n",
            "  step 400 | batch_loss 0.0001\n",
            "  step 600 | batch_loss 0.0000\n",
            "  step 800 | batch_loss 0.0000\n",
            "  step 1000 | batch_loss 0.0000\n",
            "  step 1200 | batch_loss 0.0000\n",
            "  step 1400 | batch_loss 0.0000\n",
            "  step 1600 | batch_loss 0.0001\n",
            "  step 1800 | batch_loss 0.0000\n",
            "  step 2000 | batch_loss 0.0000\n",
            "  step 2200 | batch_loss 0.0000\n",
            "  step 2400 | batch_loss 0.0000\n",
            "Epoch 4 | train 0.0000 | val 0.0007\n",
            "  step 200 | batch_loss 0.0000\n",
            "  step 400 | batch_loss 0.0000\n",
            "  step 600 | batch_loss 0.0000\n",
            "  step 800 | batch_loss 0.0000\n",
            "  step 1000 | batch_loss 0.0000\n",
            "  step 1200 | batch_loss 0.0000\n",
            "  step 1400 | batch_loss 0.0000\n",
            "  step 1600 | batch_loss 0.0000\n",
            "  step 1800 | batch_loss 0.0000\n",
            "  step 2000 | batch_loss 0.0000\n",
            "  step 2200 | batch_loss 0.0000\n",
            "  step 2400 | batch_loss 0.0000\n",
            "Epoch 5 | train 0.0000 | val 0.0001\n",
            "  saved best.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#10) 테스트 평가 + (선택) 라벨 반올림 정확도"
      ],
      "metadata": {
        "id": "QvpdmOvibs81"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# best 모델 로드\n",
        "model.load_state_dict(torch.load(\"/content/mmt_best.pt\", map_location=device))\n",
        "\n",
        "test_mse = evaluate(model, dl_test, device)\n",
        "print(\"TEST MSE:\", test_mse)\n",
        "\n",
        "# 라벨 0~3으로 rounding해서 accuracy도 같이(참고용)\n",
        "model.eval()\n",
        "ys=[]; yh=[]\n",
        "with torch.no_grad():\n",
        "    for batch in dl_test:\n",
        "        sen = batch[\"sensor_window\"].to(device)\n",
        "        img = batch[\"ir_images\"].to(device)\n",
        "        y   = batch[\"target\"].cpu().numpy()\n",
        "        pred = model(sen,img).cpu().numpy()\n",
        "        ys.append(y); yh.append(pred)\n",
        "\n",
        "ys = np.concatenate(ys)\n",
        "yh = np.concatenate(yh)\n",
        "\n",
        "yh_round = np.clip(np.rint(yh), 0, 3)\n",
        "acc = (yh_round == ys).mean()\n",
        "mae = np.mean(np.abs(yh - ys))\n",
        "print(\"TEST rounded accuracy:\", acc)\n",
        "print(\"TEST MAE:\", mae)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lGPXqTFMPNJ",
        "outputId": "13ad79bd-2110-4bf2-8520-f949efdc2095"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST MSE: 7.574634672008114e-05\n",
            "TEST rounded accuracy: 1.0\n",
            "TEST MAE: 0.008703235\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "eX0A2254bt2p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#지금 결과는 “너무 좋아서 의심해야 하는” 전형적인 패턴\n",
        "* rounded accuracy = 1.0, train loss=0.0000에 가까움, MAE=0.012면 거의 완벽 예측인데, 현실 데이터(열화 예지/상태 예측)에서는 보통 이렇게 안 나와.\n",
        "\n",
        "* 즉, 모델이 천재라서라기보다 누수(leakage) 또는 라벨이 사실상 고정/"
      ],
      "metadata": {
        "id": "xO-_JtMQXQiB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ok=0\n",
        "for p in need_bins:\n",
        "    ok += int(cache_one(p))\n",
        "print(\"cached total:\", ok, \"/\", len(need_bins))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q__vXpvKXI2a",
        "outputId": "59d5650c-2771-4972-ddfe-afe9280ad053"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cached total: 94436 / 94436\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#검증\n",
        "\n",
        "# 가장 흔한 원인 3가지\n",
        "\n",
        "\n",
        "(A) 라벨이 에피소드 내에서 거의 변하지 않는다\n",
        "\n",
        "에피소드마다 상태(0~3)가 거의 고정이면, 미래(t+30)도 지금(t)과 같아서 그냥 “현재 상태”만 알아도 맞춤.\n",
        "\n",
        "✅ 체크: 에피소드 내 라벨 변화율(전이 횟수) 보기\n",
        "\n",
        "\n",
        "\n",
        "(B) 우리가 만든 “에피소드” 정의가 너무 커서, split이 사실상 같은 흐름을 공유한다\n",
        "\n",
        "episode split 자체는 했지만, episode를 (prefix,id,mmdd)로 묶었잖아.\n",
        "만약 같은 운행이 날짜/폴더가 달라져도 같은 시퀀스가 분산되어 있거나, 혹은 파일명 규칙이 섞여 “다른 에피소드”로 잘못 쪼개졌다면 누수가 생길 수 있어.\n",
        "\n",
        "✅ 체크: train/val/test에 동일한 img-id나 동일 stem이 들어가는지 확인\n",
        "\n",
        "\n",
        "\n",
        "(C) 라벨 JSON을 잘못 파싱해서 “항상 0 또는 1” 같은 값만 뽑는 경우\n",
        "\n",
        "load_label_json()이 중첩 구조에서 엉뚱한 숫자(예: 장비번호, 누적일수)를 라벨로 착각해 거의 일정한 값만 반환할 수 있어.\n",
        "\n",
        "✅ 체크: 라벨 분포(0/1/2/3)와 JSON 원문에서 어떤 경로로 뽑혔는지 샘플링 확인"
      ],
      "metadata": {
        "id": "xWppXB0UgOJJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#검증 1) 라벨 분포(Train/Val/Test 각각)"
      ],
      "metadata": {
        "id": "pJhD2PDvXnHW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def label_dist(samples_list, n=20000):\n",
        "    ys=[]\n",
        "    for i,(epi_idx,t) in enumerate(samples_list[:n]):\n",
        "        _, ks = episodes[epi_idx]\n",
        "        y = load_label_json(records[ks[t+HORIZON]][\"json\"])\n",
        "        ys.append(y)\n",
        "    ys = np.array(ys)\n",
        "    uniq, cnt = np.unique(ys, return_counts=True)\n",
        "    return dict(zip(uniq.tolist(), cnt.tolist()))\n",
        "\n",
        "print(\"train label dist:\", label_dist(train_s))\n",
        "print(\"val   label dist:\", label_dist(val_s))\n",
        "print(\"test  label dist:\", label_dist(test_s))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sx77yuw6XK8p",
        "outputId": "42daf966-9c21-43e3-d3fc-a868b6573131"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train label dist: {1: 20000}\n",
            "val   label dist: {1: 9469}\n",
            "test  label dist: {1: 11333}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#검증 2) “현재(t)” 라벨과 “미래(t+30)” 라벨이 얼마나 같은지"
      ],
      "metadata": {
        "id": "40jKEhREXpz_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def same_rate(samples_list, n=20000):\n",
        "    same=0; total=0\n",
        "    for (epi_idx,t) in samples_list[:n]:\n",
        "        _, ks = episodes[epi_idx]\n",
        "        y_now = load_label_json(records[ks[t]][\"json\"])\n",
        "        y_fut = load_label_json(records[ks[t+HORIZON]][\"json\"])\n",
        "        if y_now is None or y_fut is None:\n",
        "            continue\n",
        "        same += int(y_now == y_fut)\n",
        "        total += 1\n",
        "    return same/total if total else None\n",
        "\n",
        "print(\"train y(t)==y(t+30):\", same_rate(train_s))\n",
        "print(\"val   y(t)==y(t+30):\", same_rate(val_s))\n",
        "print(\"test  y(t)==y(t+30):\", same_rate(test_s))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDq6dnxpgQPX",
        "outputId": "a8f4abd8-c0ff-4c19-d32a-1507ca13d9c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train y(t)==y(t+30): 1.0\n",
            "val   y(t)==y(t+30): 1.0\n",
            "test  y(t)==y(t+30): 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#검증 3) 에피소드 내부 라벨 전이(변화) 횟수"
      ],
      "metadata": {
        "id": "28uTvP12Xsxj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def episode_transitions(epi_idx, max_len=1200):\n",
        "    _, ks = episodes[epi_idx]\n",
        "    L = min(len(ks), max_len)\n",
        "    ys=[]\n",
        "    for i in range(L):\n",
        "        y = load_label_json(records[ks[i]][\"json\"])\n",
        "        ys.append(y)\n",
        "    # None 제거\n",
        "    ys = [y for y in ys if y is not None]\n",
        "    trans = sum(int(ys[i]!=ys[i-1]) for i in range(1,len(ys)))\n",
        "    return len(ys), trans\n",
        "\n",
        "# 몇 개만 보기\n",
        "for epi_idx in [0, 1, 2, 3, 4]:\n",
        "    L, tr = episode_transitions(epi_idx)\n",
        "    print(f\"episode {epi_idx}: len={L}, transitions={tr}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDqFE8RjgSD4",
        "outputId": "6ee78a74-3248-4811-b2f5-b11479ed0ca9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "episode 0: len=361, transitions=0\n",
            "episode 1: len=903, transitions=0\n",
            "episode 2: len=1200, transitions=0\n",
            "episode 3: len=1200, transitions=0\n",
            "episode 4: len=1200, transitions=0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"y true min/max:\", ys.min(), ys.max())\n",
        "print(\"y pred min/max:\", yh.min(), yh.max())\n",
        "print(\"pred sample:\", yh[:10])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKP-m4W1gTz0",
        "outputId": "a495be67-ce12-4c48-e179-49772aeb19a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y true min/max: 1.0 1.0\n",
            "y pred min/max: 1.0085742 1.0087517\n",
            "pred sample: [1.0087075 1.0086893 1.0086706 1.0087031 1.0087147 1.0086861 1.0087025\n",
            " 1.0086948 1.0086625 1.0086873]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#결론\n",
        "\n",
        " 파이프라인에서 “라벨(y)”은\n",
        "\n",
        "* train/val/test 전부 1만 존재하고\n",
        "\n",
        "* y(t) == y(t+30) 항상 참\n",
        "\n",
        "* 에피소드 내부 전이(변화) 0\n",
        "\n",
        "즉 모델이 잘한 게 아니라, 우리가 가져온 y가 ‘항상 1’로 고정돼 있어서 정확도 1.0이 나온 거야.\n",
        "\n",
        "이건 2가지 중 하나야:\n",
        "\n",
        "1. 라벨 JSON에서 우리가 뽑는 값이 “진짜 라벨”이 아니라, JSON 안에 있는 어떤 숫자(예: 장비ID/운영일/카운트 등)를 잘못 집어서 항상 1이 나오는 경우\n",
        "\n",
        "2. AIHub 라벨 파일 자체가 “정상(1)”만 포함된 subset인데, 그럼 데이터셋 목표와 안 맞음(가능성 낮음).\n",
        "→ 네 데이터 규모/구성상 1)일 확률이 거의 확실."
      ],
      "metadata": {
        "id": "Yp0MMkMSXxtZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 진짜 라벨 경로”를 찾아서 파서를 고정해야 함\n",
        "\n",
        "지금 필요한 건 라벨 JSON 구조를 실제로 확인해서,\n",
        "\n",
        "어떤 키/경로에 0~3이 있는지 찾아내고\n",
        "\n",
        "그 경로로만 라벨을 읽도록 load_label_json()을 바꾸는 것."
      ],
      "metadata": {
        "id": "laGChauMX-Cu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1) 라벨 JSON 20개를 “키 구조”까지 자동 분석해서 후보를 뽑는 코드"
      ],
      "metadata": {
        "id": "i1vH2LRhlbR5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "from collections import defaultdict, Counter\n",
        "import random\n",
        "\n",
        "# complete_keys에서 json 경로 샘플링\n",
        "json_paths = [records[k][\"json\"] for k in complete_keys]\n",
        "random.seed(42)\n",
        "sample_paths = random.sample(json_paths, 30)\n",
        "\n",
        "def collect_paths(obj, prefix=\"\"):\n",
        "    out = []\n",
        "    if isinstance(obj, dict):\n",
        "        for k,v in obj.items():\n",
        "            out += collect_paths(v, prefix + f\".{k}\")\n",
        "    elif isinstance(obj, list):\n",
        "        for i,v in enumerate(obj[:20]):  # 너무 길면 앞 20개만\n",
        "            out += collect_paths(v, prefix + f\"[{i}]\")\n",
        "    else:\n",
        "        out.append((prefix, obj))\n",
        "    return out\n",
        "\n",
        "path_counter = Counter()\n",
        "value_examples = defaultdict(list)\n",
        "\n",
        "for p in sample_paths:\n",
        "    try:\n",
        "        d = json.loads(Path(p).read_text(encoding=\"utf-8\", errors=\"replace\"))\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "    for path, val in collect_paths(d, prefix=\"$\"):\n",
        "        # 0~3 후보(정수/실수/문자열 모두)\n",
        "        try:\n",
        "            vv = int(float(val))\n",
        "            if 0 <= vv <= 3:\n",
        "                path_counter[path] += 1\n",
        "                if len(value_examples[path]) < 5:\n",
        "                    value_examples[path].append(vv)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "print(\"=== candidate paths that yield values in [0..3] ===\")\n",
        "for path, cnt in path_counter.most_common(20):\n",
        "    print(f\"{cnt:>2}x  {path}  examples={value_examples[path]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Jbb7rOogYqm",
        "outputId": "5a8507ba-6472-431f-a95d-a626df2be174"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== candidate paths that yield values in [0..3] ===\n",
            "30x  $.meta_info[0].duration_time  examples=[1, 1, 1, 1, 1]\n",
            "30x  $.sensor_data[0].PM10[0].trend  examples=[1, 1, 1, 1, 1]\n",
            "30x  $.sensor_data[0].PM2.5[0].trend  examples=[1, 1, 1, 1, 1]\n",
            "30x  $.sensor_data[0].PM1.0[0].trend  examples=[1, 1, 1, 1, 1]\n",
            "30x  $.sensor_data[0].NTC[0].trend  examples=[1, 1, 1, 1, 1]\n",
            "30x  $.sensor_data[0].CT1[0].trend  examples=[1, 1, 1, 1, 1]\n",
            "30x  $.sensor_data[0].CT2[0].trend  examples=[1, 1, 1, 1, 1]\n",
            "30x  $.sensor_data[0].CT3[0].trend  examples=[1, 1, 1, 1, 1]\n",
            "30x  $.sensor_data[0].CT4[0].trend  examples=[1, 1, 1, 1, 1]\n",
            "30x  $.annotations[0].tagging[0].state  examples=[0, 0, 3, 0, 0]\n",
            "30x  $.external_data[0].ex_temperature[0].trend  examples=[1, 1, 1, 1, 1]\n",
            "30x  $.external_data[0].ex_humidity[0].trend  examples=[1, 1, 1, 1, 1]\n",
            "30x  $.external_data[0].ex_illuminance[0].trend  examples=[1, 1, 1, 1, 1]\n",
            "28x  $.sensor_data[0].CT1[0].value  examples=[2, 2, 2, 1, 2]\n",
            "23x  $.sensor_data[0].CT3[0].value  examples=[0, 0, 0, 0, 1]\n",
            "22x  $.sensor_data[0].CT4[0].value  examples=[0, 0, 0, 0, 0]\n",
            "20x  $.sensor_data[0].CT2[0].value  examples=[1, 1, 0, 1, 1]\n",
            " 1x  $.ir_data[0].temp_max[0].Y_Tmax  examples=[1]\n",
            " 1x  $.ir_data[0].temp_max[0].X_Tmax  examples=[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2) 지금 당장 “항상 1”이 뽑히는 이유를 확인하는 코드 (현재 파서 디버그)"
      ],
      "metadata": {
        "id": "EJGEvvYLYCn7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def debug_label(path: str):\n",
        "    d = json.loads(Path(path).read_text(encoding=\"utf-8\", errors=\"replace\"))\n",
        "    y = load_label_json(path)\n",
        "    return y, d\n",
        "\n",
        "for p in sample_paths[:5]:\n",
        "    y, d = debug_label(p)\n",
        "    print(\"json:\", p)\n",
        "    print(\"parsed y:\", y)\n",
        "    # 상위 키만 출력\n",
        "    if isinstance(d, dict):\n",
        "        print(\"top keys:\", list(d.keys())[:30])\n",
        "    print(\"-\"*60)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDY5vwEMlZck",
        "outputId": "694b1776-11ec-4a9e-ceb8-3ac7e24a9bfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "json: /content/data_71802_local/extracted/VL_oht_18_oht18_0826_2155/oht18_0826_215736.json\n",
            "parsed y: 1\n",
            "top keys: ['meta_info', 'sensor_data', 'ir_data', 'annotations', 'external_data']\n",
            "------------------------------------------------------------\n",
            "json: /content/data_71802_local/extracted/TL_oht_15_oht15_0826_2126/oht15_0826_212628.json\n",
            "parsed y: 1\n",
            "top keys: ['meta_info', 'sensor_data', 'ir_data', 'annotations', 'external_data']\n",
            "------------------------------------------------------------\n",
            "json: /content/data_71802_local/extracted/TL_oht_02_oht02_0920_1020/oht02_0920_102525.json\n",
            "parsed y: 1\n",
            "top keys: ['meta_info', 'sensor_data', 'ir_data', 'annotations', 'external_data']\n",
            "------------------------------------------------------------\n",
            "json: /content/data_71802_local/extracted/TL_agv_14_agv14_0903_0650/agv14_0903_065301.json\n",
            "parsed y: 1\n",
            "top keys: ['meta_info', 'sensor_data', 'ir_data', 'annotations', 'external_data']\n",
            "------------------------------------------------------------\n",
            "json: /content/data_71802_local/extracted/TL_oht_06_oht06_0901_1310/oht06_0901_131612.json\n",
            "parsed y: 1\n",
            "top keys: ['meta_info', 'sensor_data', 'ir_data', 'annotations', 'external_data']\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ 진짜 라벨:\n",
        " `$.annotations[0].tagging[0].state` (예시가 0, 3 등으로 변함)"
      ],
      "metadata": {
        "id": "Iu1L4JrsYIDE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1) 라벨 파서 교체 (정답: annotations→tagging→state)"
      ],
      "metadata": {
        "id": "JltvylNTmHKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "def load_label_json_strict(path: str):\n",
        "    \"\"\"\n",
        "    정답 라벨: $.annotations[0].tagging[0].state\n",
        "    실패하면 None 반환 (필터링에서 제거)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        d = json.loads(Path(path).read_text(encoding=\"utf-8\", errors=\"replace\"))\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        v = d[\"annotations\"][0][\"tagging\"][0][\"state\"]\n",
        "        v = int(float(v))\n",
        "        if 0 <= v <= 3:\n",
        "            return v\n",
        "        return None\n",
        "    except:\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "c2tLz6KrldxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2) 라벨 분포/전이 재검증 (이제 정상이어야 함)"
      ],
      "metadata": {
        "id": "HcmMK5jumPho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def label_dist_strict(samples_list, n=20000):\n",
        "    ys=[]\n",
        "    for (epi_idx,t) in samples_list[:n]:\n",
        "        _, ks = episodes[epi_idx]\n",
        "        y = load_label_json_strict(records[ks[t+HORIZON]][\"json\"])\n",
        "        if y is not None:\n",
        "            ys.append(y)\n",
        "    ys = np.array(ys)\n",
        "    uniq, cnt = np.unique(ys, return_counts=True)\n",
        "    return dict(zip(uniq.tolist(), cnt.tolist())), len(ys)\n",
        "\n",
        "# samples_valid 다시 만들기\n",
        "samples_valid=[]\n",
        "for epi_idx, t in samples:\n",
        "    _, ks = episodes[epi_idx]\n",
        "    y = load_label_json_strict(records[ks[t+HORIZON]][\"json\"])\n",
        "    if y is not None:\n",
        "        samples_valid.append((epi_idx,t))\n",
        "\n",
        "print(\"samples_valid (strict):\", len(samples_valid))\n",
        "\n",
        "# 분포 보기(전체 samples_valid 기준이 아니라, split 전이라 임시로 일부만)\n",
        "dist, m = label_dist_strict(samples_valid, n=min(20000, len(samples_valid)))\n",
        "print(\"label dist (strict, sample):\", dist, \"n_used=\", m)\n",
        "\n",
        "# y(t)==y(t+30) 비율 다시 보기\n",
        "def same_rate_strict(samples_list, n=20000):\n",
        "    same=0; total=0\n",
        "    for (epi_idx,t) in samples_list[:n]:\n",
        "        _, ks = episodes[epi_idx]\n",
        "        y_now = load_label_json_strict(records[ks[t]][\"json\"])\n",
        "        y_fut = load_label_json_strict(records[ks[t+HORIZON]][\"json\"])\n",
        "        if y_now is None or y_fut is None:\n",
        "            continue\n",
        "        same += int(y_now == y_fut)\n",
        "        total += 1\n",
        "    return same/total if total else None\n",
        "\n",
        "print(\"y(t)==y(t+30) strict:\", same_rate_strict(samples_valid, n=min(20000, len(samples_valid))))\n",
        "\n",
        "# 에피소드 전이 다시 확인\n",
        "def episode_transitions_strict(epi_idx, max_len=1200):\n",
        "    _, ks = episodes[epi_idx]\n",
        "    L = min(len(ks), max_len)\n",
        "    ys=[]\n",
        "    for i in range(L):\n",
        "        y = load_label_json_strict(records[ks[i]][\"json\"])\n",
        "        if y is not None:\n",
        "            ys.append(y)\n",
        "    trans = sum(int(ys[i]!=ys[i-1]) for i in range(1,len(ys)))\n",
        "    return len(ys), trans, (ys[:20] if ys else [])\n",
        "\n",
        "for epi_idx in [0,1,2,3,4]:\n",
        "    L,tr,head = episode_transitions_strict(epi_idx)\n",
        "    print(f\"episode {epi_idx}: len={L}, transitions={tr}, head={head}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WR3X8memFk3",
        "outputId": "1f3ba43f-5c7a-4e5a-8b38-33616ff5dc28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "samples_valid (strict): 100955\n",
            "label dist (strict, sample): {0: 7980, 1: 5108, 2: 5082, 3: 1830} n_used= 20000\n",
            "y(t)==y(t+30) strict: 0.6685\n",
            "episode 0: len=361, transitions=3, head=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "episode 1: len=903, transitions=11, head=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "episode 2: len=1200, transitions=15, head=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "episode 3: len=1200, transitions=15, head=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "episode 4: len=1200, transitions=15, head=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3) split 다시 만들기 (strict samples_valid 기준)"
      ],
      "metadata": {
        "id": "h45ZRgAbmVDm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "\n",
        "def split_by_episode(samples_valid, ratios=(0.8,0.1,0.1), seed=SEED):\n",
        "    random.seed(seed)\n",
        "    epi_to = defaultdict(list)\n",
        "    for e,t in samples_valid:\n",
        "        epi_to[e].append((e,t))\n",
        "    epi_ids = list(epi_to.keys())\n",
        "    random.shuffle(epi_ids)\n",
        "    n=len(epi_ids)\n",
        "    n_tr=int(n*ratios[0]); n_va=int(n*ratios[1])\n",
        "    tr=set(epi_ids[:n_tr]); va=set(epi_ids[n_tr:n_tr+n_va]); te=set(epi_ids[n_tr+n_va:])\n",
        "    train=[s for e in tr for s in epi_to[e]]\n",
        "    val  =[s for e in va for s in epi_to[e]]\n",
        "    test =[s for e in te for s in epi_to[e]]\n",
        "    return train,val,test,(len(tr),len(va),len(te))\n",
        "\n",
        "train_s, val_s, test_s, epi_counts = split_by_episode(samples_valid)\n",
        "print(\"episode split:\", epi_counts)\n",
        "print(\"sample split :\", len(train_s), len(val_s), len(test_s))\n",
        "\n",
        "print(\"train label dist:\", label_dist_strict(train_s)[0])\n",
        "print(\"val   label dist:\", label_dist_strict(val_s)[0])\n",
        "print(\"test  label dist:\", label_dist_strict(test_s)[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SF8ojBZmKCR",
        "outputId": "9ca31d7b-3832-478c-eb64-33774b075a1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "episode split: (148, 18, 19)\n",
            "sample split : 80153 9469 11333\n",
            "train label dist: {0: 7966, 1: 5118, 2: 5116, 3: 1800}\n",
            "val   label dist: {0: 4715, 1: 1994, 2: 2010, 3: 750}\n",
            "test  label dist: {0: 4502, 1: 2879, 2: 2902, 3: 1050}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = float(load_label_json_strict(records[ks[t+HORIZON]][\"json\"]))\n"
      ],
      "metadata": {
        "id": "vHPOCDNSmK5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제야 “예측 문제”가 제대로 정의된 상태야.\n",
        "\n",
        "* 라벨 분포가 0~3로 잘 나뉨(샘플 기준 0이 많고 3이 적은 불균형 존재)\n",
        "\n",
        "* y(t)==y(t+30)이 0.6685 → “그냥 현재값 복사” 베이스라인 정확도는 약 66.9%\n",
        "\n",
        "* 에피소드 전이도 생김(3~15회) → 미래예측 의미 있음"
      ],
      "metadata": {
        "id": "1Z88WmtOn5py"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "xUSxglMKn_u0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 해야 할 건 딱 2가지 수정이야:\n",
        "\n",
        "1. Dataset의 target을 load_label_json_strict로 교체\n",
        "\n",
        "2. 평가는 회귀(MSE/MAE) + 분류(rounded accuracy + confusion)를 같이 보되, 불균형 때문에 macro F1도 같이 보는 게 좋아."
      ],
      "metadata": {
        "id": "hWX8neBuYWeN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#A) split 다시 만들고(train/val/test)"
      ],
      "metadata": {
        "id": "4R-N6M7VUmPt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_s, val_s, test_s, epi_counts = split_by_episode(samples_valid)\n",
        "print(\"episode split:\", epi_counts)\n",
        "print(\"sample split :\", len(train_s), len(val_s), len(test_s))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBTo-hsdmK3N",
        "outputId": "f7a203cc-5869-4c91-d4ea-ef1b4fefd121"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "episode split: (148, 18, 19)\n",
            "sample split : 80153 9469 11333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#B) Dataset 수정: target만 strict로"
      ],
      "metadata": {
        "id": "DLkgT6IqYeD5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 기존:\n",
        "# y = float(load_label_json(records[ks[t+HORIZON]][\"json\"]))\n",
        "\n",
        "# 수정:\n",
        "y = float(load_label_json_strict(records[ks[t+HORIZON]][\"json\"]))\n"
      ],
      "metadata": {
        "id": "nKbr6tSymK04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b = ds_train[0]\n",
        "print(\"target example:\", b[\"target\"].item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HR9wxd0ZmKyC",
        "outputId": "9a59bf6d-deff-4c7f-c405-a5d36f07d80b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target example: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#C) (권장) 불균형 보정: weighted loss로 학습 안정화"
      ],
      "metadata": {
        "id": "uu6Yd0gGYgNq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "def get_train_label_counts(train_s, max_n=50000):\n",
        "    ys=[]\n",
        "    for (epi_idx,t) in train_s[:max_n]:\n",
        "        _, ks = episodes[epi_idx]\n",
        "        y = load_label_json_strict(records[ks[t+HORIZON]][\"json\"])\n",
        "        ys.append(int(y))\n",
        "    c = Counter(ys)\n",
        "    return c\n",
        "\n",
        "cnt = get_train_label_counts(train_s)\n",
        "print(\"train label counts:\", cnt)\n",
        "\n",
        "# inverse freq weights (0~3)\n",
        "total = sum(cnt.values())\n",
        "w = np.array([total/(cnt.get(i,1)) for i in range(4)], dtype=np.float32)\n",
        "w = w / w.mean()  # scale normalize\n",
        "print(\"class weights:\", w)\n",
        "class_w = torch.tensor(w)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvcpeAciUsDU",
        "outputId": "35f9f6ae-a0c8-47e1-eda6-6280569d0406"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train label counts: Counter({0: 20537, 2: 12536, 1: 12457, 3: 4470})\n",
            "class weights: [0.4503855 0.7425196 0.7378404 2.0692544]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "def get_train_label_counts(train_s, max_n=50000):\n",
        "    ys=[]\n",
        "    for (epi_idx,t) in train_s[:max_n]:\n",
        "        _, ks = episodes[epi_idx]\n",
        "        y = load_label_json_strict(records[ks[t+HORIZON]][\"json\"])\n",
        "        ys.append(int(y))\n",
        "    c = Counter(ys)\n",
        "    return c\n",
        "\n",
        "cnt = get_train_label_counts(train_s)\n",
        "print(\"train label counts:\", cnt)\n",
        "\n",
        "# inverse freq weights (0~3)\n",
        "total = sum(cnt.values())\n",
        "w = np.array([total/(cnt.get(i,1)) for i in range(4)], dtype=np.float32)\n",
        "w = w / w.mean()  # scale normalize\n",
        "print(\"class weights:\", w)\n",
        "class_w = torch.tensor(w)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4L8OAy6gUumE",
        "outputId": "af038f1a-943b-47a4-84b2-925cfc9c5f8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train label counts: Counter({0: 20537, 2: 12536, 1: 12457, 3: 4470})\n",
            "class weights: [0.4503855 0.7425196 0.7378404 2.0692544]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class WeightedMSE(nn.Module):\n",
        "    def __init__(self, class_w: torch.Tensor):\n",
        "        super().__init__()\n",
        "        self.register_buffer(\"w\", class_w.float())\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        # target: float(0~3) -> class index\n",
        "        idx = torch.clamp(target.round().long(), 0, 3)\n",
        "        ww = self.w[idx]\n",
        "        return torch.mean(ww * (pred - target)**2)\n",
        "\n",
        "loss_fn = WeightedMSE(class_w.to(device))\n"
      ],
      "metadata": {
        "id": "GzeDNY_FUwc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#D) 평가: MSE/MAE + rounded accuracy + confusion + macro F1"
      ],
      "metadata": {
        "id": "cC0CjQoSYjGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def eval_metrics(model, loader, device):\n",
        "    model.eval()\n",
        "    ys=[]; yh=[]\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            sen = batch[\"sensor_window\"].to(device)\n",
        "            img = batch[\"ir_images\"].to(device)\n",
        "            y   = batch[\"target\"].cpu().numpy()\n",
        "            pred = model(sen,img).cpu().numpy()\n",
        "            ys.append(y); yh.append(pred)\n",
        "    y = np.concatenate(ys)\n",
        "    p = np.concatenate(yh)\n",
        "\n",
        "    mse = np.mean((p - y)**2)\n",
        "    mae = np.mean(np.abs(p - y))\n",
        "\n",
        "    pr = np.clip(np.rint(p), 0, 3).astype(int)\n",
        "    yt = y.astype(int)\n",
        "\n",
        "    acc = (pr == yt).mean()\n",
        "\n",
        "    # confusion + macro f1\n",
        "    cm = np.zeros((4,4), dtype=int)\n",
        "    for a,b in zip(yt, pr):\n",
        "        cm[a,b] += 1\n",
        "\n",
        "    f1s=[]\n",
        "    for cls in range(4):\n",
        "        tp = cm[cls,cls]\n",
        "        fp = cm[:,cls].sum() - tp\n",
        "        fn = cm[cls,:].sum() - tp\n",
        "        prec = tp/(tp+fp+1e-9)\n",
        "        rec  = tp/(tp+fn+1e-9)\n",
        "        f1 = 2*prec*rec/(prec+rec+1e-9)\n",
        "        f1s.append(f1)\n",
        "    macro_f1 = float(np.mean(f1s))\n",
        "\n",
        "    return {\"mse\": float(mse), \"mae\": float(mae), \"acc_round\": float(acc), \"macro_f1\": macro_f1, \"cm\": cm}\n",
        "\n",
        "# 학습 후:\n",
        "print(\"VAL :\", eval_metrics(model, dl_val, device))\n",
        "print(\"TEST:\", eval_metrics(model, dl_test, device))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYAqQ80PU0PD",
        "outputId": "e3feccd0-fb83-440c-9e2a-dcd33092e619"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL : {'mse': 7.575827476102859e-05, 'mae': 0.008703900501132011, 'acc_round': 1.0, 'macro_f1': 0.24999999987497357, 'cm': array([[   0,    0,    0,    0],\n",
            "       [   0, 9469,    0,    0],\n",
            "       [   0,    0,    0,    0],\n",
            "       [   0,    0,    0,    0]])}\n",
            "TEST: {'mse': 7.574661867693067e-05, 'mae': 0.008703234605491161, 'acc_round': 1.0, 'macro_f1': 0.24999999987497795, 'cm': array([[    0,     0,     0,     0],\n",
            "       [    0, 11333,     0,     0],\n",
            "       [    0,     0,     0,     0],\n",
            "       [    0,     0,     0,     0]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "RCGlQ_WQVNye"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#E) 가장 중요한 베이스라인 2개(꼭 비교해야 함)"
      ],
      "metadata": {
        "id": "d7IacDcDYpUf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def baseline_hold(samples_list, n=20000):\n",
        "    ys=[]; pr=[]\n",
        "    for (epi_idx,t) in samples_list[:n]:\n",
        "        _, ks = episodes[epi_idx]\n",
        "        y_now = load_label_json_strict(records[ks[t]][\"json\"])\n",
        "        y_fut = load_label_json_strict(records[ks[t+HORIZON]][\"json\"])\n",
        "        if y_now is None or y_fut is None:\n",
        "            continue\n",
        "        ys.append(y_fut)\n",
        "        pr.append(y_now)\n",
        "    ys=np.array(ys); pr=np.array(pr)ㅌ\n",
        "    return (ys==pr).mean()\n",
        "\n",
        "print(\"baseline hold acc (test):\", baseline_hold(test_s, n=20000))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZMDUepvVOk8",
        "outputId": "438526a2-b7e0-4844-c51f-1083b26bbd84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "baseline hold acc (test): 0.6744021882996559\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def baseline_majority(samples_list, majority=0, n=20000):\n",
        "    ys=[]\n",
        "    for (epi_idx,t) in samples_list[:n]:\n",
        "        _, ks = episodes[epi_idx]\n",
        "        y = load_label_json_strict(records[ks[t+HORIZON]][\"json\"])\n",
        "        if y is not None:\n",
        "            ys.append(y)\n",
        "    ys=np.array(ys)\n",
        "    return (ys==majority).mean()\n",
        "\n",
        "print(\"baseline majority-0 acc (test):\", baseline_majority(test_s, 0, n=20000))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETt0VXglVOip",
        "outputId": "1a123d28-de42-46b9-c602-776eb91b326d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "baseline majority-0 acc (test): 0.3972469778522898\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#hold baseline 테스트 정확도(정식 계산)"
      ],
      "metadata": {
        "id": "YGQGEz44Y4YA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"baseline hold acc (test):\", baseline_hold(test_s, n=50000))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "co2r8quLsS1H",
        "outputId": "bf00720d-b276-4973-ae8e-2ce524b41721"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "baseline hold acc (test): 0.6744021882996559\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ds_train 만든 뒤\n",
        "tmp = [ds_train[i][\"target\"].item() for i in range(20)]\n",
        "print(\"targets sample:\", tmp)\n",
        "print(\"unique:\", sorted(set(int(x) for x in tmp)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8uWTI2CsTJ2",
        "outputId": "1b0b0c57-de40-49c9-e221-9d838305e97f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "targets sample: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
            "unique: [1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "결과\n",
        "\n",
        "✅ 너 Dataset이 아직도 “옛 load_label_json(항상 1)”을 쓰고 있거나,\n",
        "혹은 strict 함수로 바꿨더라도 t+HORIZON이 아니라 다른 경로/다른 json을 읽고 있어서 결과가 다시 1로 고정된 거야.\n",
        "\n",
        "지금 네 검증(라벨 분포, 전이)은 strict 파서로 정상이었잖아.\n",
        "그런데 Dataset 샘플이 전부 1이면, Dataset 내부 y만 잘못 연결된 것이 확실해."
      ],
      "metadata": {
        "id": "NvmgC0fiZGj0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#✅ 1) Dataset 강제 교체 (strict 라벨 + 디버그 출력 포함)"
      ],
      "metadata": {
        "id": "dRPAIS0guSEI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class ForecastSingleDatasetStrict(Dataset):\n",
        "    def __init__(self, samples_list, debug=False):\n",
        "        self.samples = samples_list\n",
        "        self.debug = debug\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        epi_idx, t = self.samples[idx]\n",
        "        _, ks = episodes[epi_idx]\n",
        "\n",
        "        # --- sensor window ---\n",
        "        win_keys = ks[t-(PAST-1):t+1]\n",
        "        sw = np.stack([load_sensor_csv(records[k][\"csv\"]) for k in win_keys], axis=0).astype(np.float32)\n",
        "        sw = zscore_clip_sensor(sw, sensor_mean, sensor_std, clip=3.0)\n",
        "\n",
        "        # --- image stack ---\n",
        "        im1 = resize_img(load_thermal_cached(records[ks[t-29]][\"bin\"]))\n",
        "        im2 = resize_img(load_thermal_cached(records[ks[t-14]][\"bin\"]))\n",
        "        im3 = resize_img(load_thermal_cached(records[ks[t]][\"bin\"]))\n",
        "        img = np.stack([im1, im2, im3], axis=0).astype(np.float32)\n",
        "        img = (img - IMG_MEAN) / (IMG_STD + 1e-8)\n",
        "\n",
        "        # --- STRICT target: t+HORIZON state ---\n",
        "        json_path = records[ks[t+HORIZON]][\"json\"]\n",
        "        y = load_label_json_strict(json_path)  # <-- 핵심\n",
        "\n",
        "        # debug 모드면 실제 json 경로와 y 출력 (처음 몇 개만)\n",
        "        if self.debug and idx < 5:\n",
        "            print(\"[DEBUG] idx\", idx, \"t\", t, \"json:\", json_path, \"y:\", y)\n",
        "\n",
        "        # 방어: 혹시 None이면 (원래 samples_valid로 제거되긴 했지만)\n",
        "        if y is None:\n",
        "            y = 0\n",
        "\n",
        "        return {\n",
        "            \"sensor_window\": torch.tensor(sw, dtype=torch.float32),\n",
        "            \"ir_images\": torch.tensor(img, dtype=torch.float32),\n",
        "            \"target\": torch.tensor(float(y), dtype=torch.float32),  # 회귀용(기존 유지)\n",
        "        }\n"
      ],
      "metadata": {
        "id": "kMol2fZismW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#✅ 2) ds_train을 이걸로 다시 만들고, debug로 라벨 확인"
      ],
      "metadata": {
        "id": "YVSk9UhWZLT9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds_train = ForecastSingleDatasetStrict(train_s, debug=True)\n",
        "\n",
        "tmp = [ds_train[i][\"target\"].item() for i in range(50)]\n",
        "print(\"targets sample:\", tmp[:20])\n",
        "print(\"unique:\", sorted(set(int(x) for x in tmp)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRYLvu-luUEe",
        "outputId": "4792711d-6202-4aa9-b76e-46fd5353b245"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DEBUG] idx 0 t 29 json: /content/data_71802_local/extracted/TL_agv_06_agv06_0902_1356/agv06_0902_135727.json y: 0\n",
            "[DEBUG] idx 1 t 30 json: /content/data_71802_local/extracted/TL_agv_06_agv06_0902_1356/agv06_0902_135728.json y: 0\n",
            "[DEBUG] idx 2 t 31 json: /content/data_71802_local/extracted/TL_agv_06_agv06_0902_1356/agv06_0902_135729.json y: 0\n",
            "[DEBUG] idx 3 t 32 json: /content/data_71802_local/extracted/TL_agv_06_agv06_0902_1356/agv06_0902_135730.json y: 0\n",
            "[DEBUG] idx 4 t 33 json: /content/data_71802_local/extracted/TL_agv_06_agv06_0902_1356/agv06_0902_135731.json y: 0\n",
            "targets sample: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "unique: [0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#✅ 3) 추가로 “Dataset이 쓰는 strict y”와 “직접 계산한 y”가 같은지 검증"
      ],
      "metadata": {
        "id": "G4mvi9A-ZNd-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset이 읽는 y\n",
        "y_ds = int(ds_train[0][\"target\"].item())\n",
        "\n",
        "# 같은 인덱스를 직접 계산\n",
        "epi_idx, t = train_s[0]\n",
        "_, ks = episodes[epi_idx]\n",
        "y_direct = load_label_json_strict(records[ks[t+HORIZON]][\"json\"])\n",
        "\n",
        "print(\"y_ds:\", y_ds)\n",
        "print(\"y_direct:\", y_direct)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jz6udtibuZVv",
        "outputId": "5d627971-d16c-4a23-a7a0-03201e582d32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DEBUG] idx 0 t 29 json: /content/data_71802_local/extracted/TL_agv_06_agv06_0902_1356/agv06_0902_135727.json y: 0\n",
            "y_ds: 0\n",
            "y_direct: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "지금 debug를 보면:\n",
        "\n",
        "t=29인데 라벨을 읽는 json이 ...135727.json\n",
        "\n",
        "즉 “현재 t 시점의 json”을 읽고 있어.\n",
        "\n",
        "그런데 우리가 원하는 건 t+30 (HORIZON) 시점 라벨이야.\n",
        "\n",
        "원래 코드에서 json_path = records[ks[t+HORIZON]][\"json\"]로 되어 있는데, 출력은 그게 아닌 것처럼 보임.\n",
        "\n",
        "왜냐면, 네 파일명 규칙상 1356xx는 초 단위로 증가하는데,\n",
        "t=29면 t+30은 59초 뒤라서 1357xx가 아니라 1356xx에서 +59초가 되어야 해서 숫자가 달라져야 해.\n",
        "그런데 지금은 t=29 → 135727, t=30 → 135728… 완전 현재 인덱스랑 1:1로 움직임이야.\n",
        "즉 HORIZON이 0으로 잡혀있거나, Dataset 안에서 HORIZON이 덮였거나, 혹은 ks 리스트 자체가 이미 “t+30만큼 밀린 리스트”로 들어온 상태야.\n",
        "\n",
        "결론: 지금은 HORIZON 적용이 깨져서, “미래 라벨”을 못 보고 “현재 라벨”만 보고 있어.\n",
        "그래서 지금 샘플 50개가 전부 0인 것도 자연스러움(해당 에피소드 초반이 0 상태로 고정돼 있으니까)."
      ],
      "metadata": {
        "id": "B2OTrz3OZVv7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "#1) HORIZON이 진짜 30인지 먼저 확정 (가장 빠른 진단)"
      ],
      "metadata": {
        "id": "R7CHE_zDZXNK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"HORIZON =\", HORIZON)\n",
        "\n",
        "epi_idx, t = train_s[0]\n",
        "_, ks = episodes[epi_idx]\n",
        "\n",
        "print(\"t =\", t)\n",
        "print(\"stem(t)      =\", Path(records[ks[t]][\"json\"]).stem)\n",
        "print(\"stem(t+30)   =\", Path(records[ks[t+30]][\"json\"]).stem)\n",
        "print(\"stem(t+H)    =\", Path(records[ks[t+HORIZON]][\"json\"]).stem)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5t_18PZudHP",
        "outputId": "1c8bc308-cdb0-4a72-d90a-65aa99863837"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HORIZON = 30\n",
            "t = 29\n",
            "stem(t)      = agv06_0902_135657\n",
            "stem(t+30)   = agv06_0902_135727\n",
            "stem(t+H)    = agv06_0902_135727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2) Dataset이 “진짜로 t+HORIZON을 쓰는지” 강제 검증"
      ],
      "metadata": {
        "id": "y0N6oSuwZcPj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ForecastSingleDatasetStrict(Dataset):\n",
        "    def __init__(self, samples_list, debug=False):\n",
        "        self.samples = samples_list\n",
        "        self.debug = debug\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        epi_idx, t = self.samples[idx]\n",
        "        _, ks = episodes[epi_idx]\n",
        "\n",
        "        # STRICT target\n",
        "        jp_now = records[ks[t]][\"json\"]\n",
        "        jp_fut = records[ks[t+HORIZON]][\"json\"]\n",
        "\n",
        "        y_now = load_label_json_strict(jp_now)\n",
        "        y_fut = load_label_json_strict(jp_fut)\n",
        "\n",
        "        if self.debug and idx < 3:\n",
        "            print(\"[DEBUG] idx\", idx, \"t\", t, \"H\", HORIZON)\n",
        "            print(\"   now:\", Path(jp_now).stem, \"y_now:\", y_now)\n",
        "            print(\"   fut:\", Path(jp_fut).stem, \"y_fut:\", y_fut)\n",
        "\n",
        "        # --- 나머지는 생략(속도 위해), 일단 타깃만 검증 ---\n",
        "        return {\"target\": torch.tensor(float(y_fut), dtype=torch.float32)}\n"
      ],
      "metadata": {
        "id": "rOQ-N0fiuyHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_dbg = ForecastSingleDatasetStrict(train_s, debug=True)\n",
        "for i in range(3):\n",
        "    _ = ds_dbg[i]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkUYQBLwvBjW",
        "outputId": "907fa106-fa70-4d34-9340-38a275210371"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DEBUG] idx 0 t 29 H 30\n",
            "   now: agv06_0902_135657 y_now: 0\n",
            "   fut: agv06_0902_135727 y_fut: 0\n",
            "[DEBUG] idx 1 t 30 H 30\n",
            "   now: agv06_0902_135658 y_now: 0\n",
            "   fut: agv06_0902_135728 y_fut: 0\n",
            "[DEBUG] idx 2 t 31 H 30\n",
            "   now: agv06_0902_135659 y_now: 0\n",
            "   fut: agv06_0902_135729 y_fut: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "결론: 정상 / 지금 출력은 “HORIZON이 제대로 적용되고 있고, t+30 시점 라벨을 정확히 읽고 있다”는 뜻이야.\n",
        "\n",
        "* t=29의 현재 stem: 135657\n",
        "\n",
        "* t+30의 stem: 135727 (정확히 30초 뒤)\n",
        "\n",
        "* Dataset debug도 now/fut가 다르게 찍힘 ✅\n",
        "\n",
        "그런데 targets sample이 전부 0으로 나온 이유는 딱 하나:\n",
        "\n",
        "네가 뽑은 ds_train[0..49]는 같은 에피소드 초반 구간이고, 그 구간의 t+30 라벨이 아직 전부 0이라서 그래.\n",
        "\n",
        "아까 너가 “전체 분포”는 0~3이 섞여 있다고 확인했잖아.\n",
        "즉, Dataset 자체는 정상이고, 단지 “앞부분만 찍어보면 0만 보인다”는 거야."
      ],
      "metadata": {
        "id": "loGADle3ZpIS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "zGA2klbd8Q-m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1) Dataset 타깃 랜덤 샘플로 유니크 확인(필수)"
      ],
      "metadata": {
        "id": "jG-Tr9Wjvz-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random, numpy as np\n",
        "\n",
        "def sample_targets(ds, k=2000, seed=42):\n",
        "    random.seed(seed)\n",
        "    idxs = random.sample(range(len(ds)), k)\n",
        "    ys = [int(ds[i][\"target\"].item()) for i in idxs]\n",
        "    uniq, cnt = np.unique(ys, return_counts=True)\n",
        "    return dict(zip(uniq.tolist(), cnt.tolist()))\n",
        "\n",
        "ds_train = ForecastSingleDatasetStrict(train_s, debug=False)\n",
        "print(\"random target dist (train):\", sample_targets(ds_train, k=5000))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvGyiyYdvFqZ",
        "outputId": "4be97067-b016-473a-be6a-1e45b7c736a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "random target dist (train): {0: 2182, 1: 1217, 2: 1197, 3: 404}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2) 모델이 hold baseline(0.6744)을 이기는지"
      ],
      "metadata": {
        "id": "ZA0lTpr38WFZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ForecastSingleDatasetStrictCls(Dataset):\n",
        "    def __init__(self, samples_list):\n",
        "        self.samples = samples_list\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        epi_idx, t = self.samples[idx]\n",
        "        _, ks = episodes[epi_idx]\n",
        "\n",
        "        # sensor window\n",
        "        win_keys = ks[t-(PAST-1):t+1]\n",
        "        sw = np.stack([load_sensor_csv(records[k][\"csv\"]) for k in win_keys], axis=0).astype(np.float32)\n",
        "        sw = zscore_clip_sensor(sw, sensor_mean, sensor_std, clip=3.0)\n",
        "\n",
        "        # image stack\n",
        "        im1 = resize_img(load_thermal_cached(records[ks[t-29]][\"bin\"]))\n",
        "        im2 = resize_img(load_thermal_cached(records[ks[t-14]][\"bin\"]))\n",
        "        im3 = resize_img(load_thermal_cached(records[ks[t]][\"bin\"]))\n",
        "        img = np.stack([im1, im2, im3], axis=0).astype(np.float32)\n",
        "        img = (img - IMG_MEAN) / (IMG_STD + 1e-8)\n",
        "\n",
        "        # ✅ strict label at t+30\n",
        "        y = int(load_label_json_strict(records[ks[t+HORIZON]][\"json\"]))\n",
        "        return {\n",
        "            \"sensor_window\": torch.tensor(sw, dtype=torch.float32),\n",
        "            \"ir_images\": torch.tensor(img, dtype=torch.float32),\n",
        "            \"target\": torch.tensor(y, dtype=torch.long),\n",
        "        }\n"
      ],
      "metadata": {
        "id": "MLFZqfDDvswD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_train = ForecastSingleDatasetStrictCls(train_s)\n",
        "ds_val   = ForecastSingleDatasetStrictCls(val_s)\n",
        "ds_test  = ForecastSingleDatasetStrictCls(test_s)\n",
        "\n",
        "dl_train = DataLoader(ds_train, batch_size=32, shuffle=True,  num_workers=2, pin_memory=True)\n",
        "dl_val   = DataLoader(ds_val,   batch_size=32, shuffle=False, num_workers=2, pin_memory=True)\n",
        "dl_test  = DataLoader(ds_test,  batch_size=32, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "# quick check\n",
        "tmp = [ds_train[i][\"target\"].item() for i in range(50)]\n",
        "print(\"first50 unique:\", sorted(set(tmp)))\n",
        "print(\"random dist:\", sample_targets(ds_train, k=5000))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQZ2Fxpov3s2",
        "outputId": "7292aefd-cc17-43cf-f83d-26528cb28078"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first50 unique: [0]\n",
            "random dist: {0: 2182, 1: 1217, 2: 1197, 3: 404}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3) MMT 분류 모델 + class weight CE loss"
      ],
      "metadata": {
        "id": "3nbeRAvHwZaN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "class MMT_Cls(nn.Module):\n",
        "    def __init__(self, d_model=256, nhead=8, layers=4, patch=16, num_classes=4):\n",
        "        super().__init__()\n",
        "        self.patch = patch\n",
        "        self.img_tokens = (IMG_SIZE // patch) * (IMG_SIZE // patch)\n",
        "\n",
        "        self.img_proj = nn.Linear(patch*patch*3, d_model)\n",
        "        self.sen_proj = nn.Linear(8, d_model)\n",
        "\n",
        "        self.cls = nn.Parameter(torch.zeros(1,1,d_model))\n",
        "        self.pos = nn.Parameter(torch.zeros(1,1+self.img_tokens+PAST, d_model))\n",
        "\n",
        "        enc = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, batch_first=True)\n",
        "        self.enc = nn.TransformerEncoder(enc, num_layers=layers)\n",
        "        self.head = nn.Linear(d_model, num_classes)\n",
        "\n",
        "        nn.init.trunc_normal_(self.cls, std=0.02)\n",
        "        nn.init.trunc_normal_(self.pos, std=0.02)\n",
        "\n",
        "    def img_to_tokens(self, x):\n",
        "        B,C,H,W = x.shape\n",
        "        p = self.patch\n",
        "        patches = x.unfold(2,p,p).unfold(3,p,p)\n",
        "        patches = patches.permute(0,2,3,1,4,5).contiguous()\n",
        "        patches = patches.view(B, self.img_tokens, C*p*p)\n",
        "        return self.img_proj(patches)\n",
        "\n",
        "    def forward(self, sensor_window, ir_images):\n",
        "        B = sensor_window.size(0)\n",
        "        tok_img = self.img_to_tokens(ir_images)\n",
        "        tok_sen = self.sen_proj(sensor_window)\n",
        "        cls = self.cls.expand(B,-1,-1)\n",
        "        x = torch.cat([cls, tok_img, tok_sen], dim=1)\n",
        "        x = x + self.pos[:, :x.size(1), :]\n",
        "        h = self.enc(x)\n",
        "        return self.head(h[:,0])  # (B,4)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# class weights from train labels (샘플링)\n",
        "ys=[]\n",
        "for i in range(min(50000, len(ds_train))):\n",
        "    ys.append(int(ds_train[i][\"target\"].item()))\n",
        "cnt = Counter(ys)\n",
        "total = sum(cnt.values())\n",
        "w = np.array([total/(cnt.get(i,1)) for i in range(4)], dtype=np.float32)\n",
        "w = w / w.mean()\n",
        "class_w = torch.tensor(w, device=device)\n",
        "print(\"train label counts(sample):\", cnt)\n",
        "print(\"class weights:\", w)\n",
        "\n",
        "model = MMT_Cls().to(device)\n",
        "criterion = nn.CrossEntropyLoss(weight=class_w)\n",
        "opt = optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mp4AfEnmv6zK",
        "outputId": "794ada66-29eb-4407-bb89-920b2bd38fe3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train label counts(sample): Counter({0: 20537, 2: 12536, 1: 12457, 3: 4470})\n",
            "class weights: [0.4503855 0.7425196 0.7378404 2.0692544]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4) 평가 함수(accuracy + macroF1 + confusion)"
      ],
      "metadata": {
        "id": "bfw0xM2Y8lN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_cls(model, loader, device):\n",
        "    model.eval()\n",
        "    ys=[]; pr=[]\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            sen = batch[\"sensor_window\"].to(device)\n",
        "            img = batch[\"ir_images\"].to(device)\n",
        "            y   = batch[\"target\"].cpu().numpy()\n",
        "            logits = model(sen,img).cpu().numpy()\n",
        "            pred = logits.argmax(axis=1)\n",
        "            ys.append(y); pr.append(pred)\n",
        "\n",
        "    y = np.concatenate(ys); p = np.concatenate(pr)\n",
        "    acc = (y==p).mean()\n",
        "\n",
        "    cm = np.zeros((4,4), dtype=int)\n",
        "    for a,b in zip(y,p): cm[a,b]+=1\n",
        "\n",
        "    f1s=[]\n",
        "    for c in range(4):\n",
        "        tp=cm[c,c]\n",
        "        fp=cm[:,c].sum()-tp\n",
        "        fn=cm[c,:].sum()-tp\n",
        "        prec=tp/(tp+fp+1e-9)\n",
        "        rec =tp/(tp+fn+1e-9)\n",
        "        f1=2*prec*rec/(prec+rec+1e-9)\n",
        "        f1s.append(f1)\n",
        "\n",
        "    return float(acc), float(np.mean(f1s)), cm\n"
      ],
      "metadata": {
        "id": "BTVgr0tKwSv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5) 학습(5 epoch) + hold baseline(0.6744) 넘는지 확인"
      ],
      "metadata": {
        "id": "6xySJnRp8jAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best = -1\n",
        "EPOCHS = 5\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    model.train()\n",
        "    run=0.0; n=0\n",
        "    for step, batch in enumerate(dl_train, 1):\n",
        "        sen = batch[\"sensor_window\"].to(device)\n",
        "        img = batch[\"ir_images\"].to(device)\n",
        "        y   = batch[\"target\"].to(device)\n",
        "\n",
        "        opt.zero_grad(set_to_none=True)\n",
        "        logits = model(sen,img)\n",
        "        loss = criterion(logits, y)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        opt.step()\n",
        "\n",
        "        run += loss.item()*sen.size(0)\n",
        "        n += sen.size(0)\n",
        "\n",
        "        if step % 300 == 0:\n",
        "            print(f\"  step {step} | loss {loss.item():.4f}\")\n",
        "\n",
        "    tr_loss = run/max(n,1)\n",
        "    val_acc, val_f1, _ = eval_cls(model, dl_val, device)\n",
        "    print(f\"Epoch {epoch} | train loss {tr_loss:.4f} | val acc {val_acc:.4f} | val macroF1 {val_f1:.4f}\")\n",
        "\n",
        "    if val_acc > best:\n",
        "        best = val_acc\n",
        "        torch.save(model.state_dict(), \"/content/mmt_cls_best.pt\")\n",
        "        print(\"  saved best.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WEtGEgqwcmO",
        "outputId": "1eaca653-ec43-45db-c6b4-e8e2338ad45e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  step 300 | loss 0.6095\n",
            "  step 600 | loss 0.4940\n",
            "  step 900 | loss 0.5936\n",
            "  step 1200 | loss 0.4337\n",
            "  step 1500 | loss 0.4261\n",
            "  step 1800 | loss 0.3146\n",
            "  step 2100 | loss 0.5006\n",
            "  step 2400 | loss 0.6567\n",
            "Epoch 1 | train loss 0.6978 | val acc 0.8287 | val macroF1 0.7909\n",
            "  saved best.\n",
            "  step 300 | loss 0.4357\n",
            "  step 600 | loss 0.4063\n",
            "  step 900 | loss 0.2326\n",
            "  step 1200 | loss 0.4056\n",
            "  step 1500 | loss 0.4677\n",
            "  step 1800 | loss 0.4023\n",
            "  step 2100 | loss 0.4347\n",
            "  step 2400 | loss 0.5074\n",
            "Epoch 2 | train loss 0.4781 | val acc 0.7798 | val macroF1 0.7752\n",
            "  step 300 | loss 0.3743\n",
            "  step 600 | loss 0.4119\n",
            "  step 900 | loss 0.2725\n",
            "  step 1200 | loss 0.4307\n",
            "  step 1500 | loss 0.3747\n",
            "  step 1800 | loss 0.2696\n",
            "  step 2100 | loss 0.3951\n",
            "  step 2400 | loss 0.2141\n",
            "Epoch 3 | train loss 0.4273 | val acc 0.7576 | val macroF1 0.7726\n",
            "  step 300 | loss 0.4003\n",
            "  step 600 | loss 0.3338\n",
            "  step 900 | loss 0.2821\n",
            "  step 1200 | loss 0.6968\n",
            "  step 1500 | loss 0.4942\n",
            "  step 1800 | loss 0.6574\n",
            "  step 2100 | loss 0.2093\n",
            "  step 2400 | loss 0.6124\n",
            "Epoch 4 | train loss 0.3961 | val acc 0.8241 | val macroF1 0.8120\n",
            "  step 300 | loss 0.2766\n",
            "  step 600 | loss 0.3505\n",
            "  step 900 | loss 0.3214\n",
            "  step 1200 | loss 0.4563\n",
            "  step 1500 | loss 0.3741\n",
            "  step 1800 | loss 0.2807\n",
            "  step 2100 | loss 0.8051\n",
            "  step 2400 | loss 0.5722\n",
            "Epoch 5 | train loss 0.4139 | val acc 0.8568 | val macroF1 0.8472\n",
            "  saved best.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(\"/content/mmt_cls_best.pt\", map_location=device))\n",
        "test_acc, test_f1, test_cm = eval_cls(model, dl_test, device)\n",
        "print(\"TEST acc:\", test_acc, \" (hold baseline=0.6744)\")\n",
        "print(\"TEST macroF1:\", test_f1)\n",
        "print(\"TEST confusion:\\n\", test_cm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CiHv1LYJwe2o",
        "outputId": "05648a83-b6af-479b-d5c6-14306817f5e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST acc: 0.8103767757875232  (hold baseline=0.6744)\n",
            "TEST macroF1: 0.8036109486000743\n",
            "TEST confusion:\n",
            " [[3552  787    0  163]\n",
            " [ 440 2105  334    0]\n",
            " [  63   13 2629  197]\n",
            " [  85    0   67  898]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "결론:\n",
        "재현 파이프라인이 제대로 돌아갔고, 모델이 의미 있게 미래를 예측하고 있다는 강한 증거야.\n",
        "\n",
        "* TEST acc 0.8104 vs hold 0.6744 → +0.1360p 개선 (엄청 큼)\n",
        "\n",
        "* macro F1 0.8036 → 불균형(특히 3번 클래스 적음)에서도 균형 있게 맞춘 편\n",
        "\n",
        "* confusion도 “대각선 우세”라서 전반적으로 잘 맞음"
      ],
      "metadata": {
        "id": "eua56bXiZ8Sz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#결론 = 회귀에서 분류로 바꿈!!!\n",
        ">  왜 분류로 바꿨냐(너 상황에서 현실적인 이유)\n",
        "\n",
        "\n",
        "1) 회귀(MSE)에서 라벨이 잘못되면 티가 덜 나고 “0에 수렴” 착시가 생김\n",
        "\n",
        "* 너가 겪은 것처럼 y가 1로 고정되면 MSE는 바로 0으로 떨어져서 “학습이 잘 됐나?”처럼 보임.\n",
        "\n",
        "* 즉, 회귀는 라벨 버그를 더 늦게 발견할 수 있어.\n",
        "\n",
        "2) 분류는 “라벨 분포/전이/혼동”이 바로 드러남\n",
        "\n",
        "* CE로 돌리면 label dist가 이상하면 바로 티가 나고,\n",
        "\n",
        "* confusion matrix로 “진짜로 0~3을 구분하는지”가 한 번에 보임.\n",
        "\n",
        "* 그래서 라벨 파싱(state 경로 고정)이 제대로 됐는지 확인하는 용도로 분류가 빠름.\n",
        "\n",
        "3) 너희는 “hold baseline(0.674)”을 넘는지 빠르게 확인해야 했음\n",
        "\n",
        "* 분류 지표(acc/macroF1)가 “기준선”을 잡기에 쉬워서 우선 확인한 거야.\n",
        "\n",
        "* 즉, 분류는 재현 목적이 아니라 디버깅/검증용 브릿지로 쓴 거고,\n",
        "라벨이 정상이라는 게 확인됐으니 이제 회귀로 돌아가면 돼."
      ],
      "metadata": {
        "id": "0Uvq_i9FysD1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "_wGCrpDTx5gW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#분류 -> 회귀로 다시 바꾸기\n",
        "\n",
        "1) 모델 head\n",
        "\n",
        "* 분류: Linear(d_model, 4) (logits)\n",
        "\n",
        "* 회귀: Linear(d_model, 1) (scalar)\n",
        "\n",
        "\n",
        "\n",
        "2) loss\n",
        "\n",
        "* 분류: CrossEntropyLoss\n",
        "\n",
        "* 회귀: MSELoss 또는 SmoothL1Loss(Huber) (노이즈 있으면 Huber 추천)\n",
        "\n",
        "\n",
        "\n",
        "3) target 타입\n",
        "\n",
        "* 분류: y.long()\n",
        "\n",
        "* 회귀: y.float()\n",
        "\n",
        "\n",
        "\n",
        "4) 평가\n",
        "\n",
        "* RMSE/MAE를 기본으로 찍고\n",
        "\n",
        "* 필요하면 round/clip해서 “참고용” accuracy/macroF1도 같이 찍기"
      ],
      "metadata": {
        "id": "j3YJ2UtLzIQm"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D_9HdKVwwghz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}